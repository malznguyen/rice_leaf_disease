{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyOlNK3ieMavEdSn1Z342phd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Hệ thống phát hiện bệnh trên lá lúa sử dụng mô hình SSD300 với backbone VGG16\n","Phát hiện 4 loại bệnh chính:\n","- Bacterial Blight (Bạc lá)\n","- Blast (Đạo ôn)\n","- Brown Spot (Đốm nâu)\n","- Twisted Draft (Xoắn lá)\n","\n","Mô hình sử dụng định dạng dữ liệu COCO."],"metadata":{"id":"fSpYpmjvMMR5"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"7HV_kvFtML6W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install torch torchvision pycocotools -q\n","!pip install seaborn scikit-learn matplotlib -q"],"metadata":{"id":"IqikPykRMOps"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile config.py\n","import os\n","import torch\n","\n","# Path settings\n","DATA_ROOT = \"/content/drive/MyDrive/Coco_Dataset\"\n","TRAIN_DIR = os.path.join(DATA_ROOT, \"train\")\n","VAL_DIR = os.path.join(DATA_ROOT, \"valid\")\n","TEST_DIR = os.path.join(DATA_ROOT, \"test\")\n","\n","TRAIN_ANNO = os.path.join(TRAIN_DIR, \"_annotations.coco.json\")\n","VAL_ANNO = os.path.join(VAL_DIR, \"_annotations.coco.json\")\n","TEST_ANNO = os.path.join(TEST_DIR, \"_annotations.coco.json\")\n","\n","# Output directory for saving models and results\n","OUTPUT_DIR = \"/content/drive/MyDrive/SSD_Output\"\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# Model parameters\n","NUM_CLASSES = 5  # 4 disease classes + background class\n","MODEL_TYPE = \"ssd300_vgg16\"\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Training parameters\n","BATCH_SIZE = 16\n","NUM_WORKERS = 4\n","LEARNING_RATE = 0.001\n","MOMENTUM = 0.9\n","WEIGHT_DECAY = 0.0005\n","NUM_EPOCHS = 50\n","\n","# Scheduler parameters\n","STEP_SIZE = 20\n","GAMMA = 0.1\n","\n","\n","IMAGE_SIZE = 300\n","\n","\n","CONFIDENCE_THRESHOLD = 0.5\n","IOU_THRESHOLD = 0.5\n","\n","\n","CLASS_NAMES = [\n","    \"background\",  # Class 0 (background) is always included in SSD\n","    \"bacterial_blight\",\n","    \"blast\",\n","    \"brown_spot\",\n","    \"tungro\"\n","]\n","\n","# Paths for saving results\n","MODEL_SAVE_PATH = os.path.join(OUTPUT_DIR, \"ssd_model.pth\")\n","METRICS_SAVE_PATH = os.path.join(OUTPUT_DIR, \"metrics\")\n","CONFUSION_MATRIX_PATH = os.path.join(OUTPUT_DIR, \"confusion_matrix.png\")\n","PR_CURVE_PATH = os.path.join(OUTPUT_DIR, \"pr_curve.png\")\n","F1_CURVE_PATH = os.path.join(OUTPUT_DIR, \"f1_curve.png\")\n","\n","# Create directories\n","os.makedirs(METRICS_SAVE_PATH, exist_ok=True)\n","\n","def print_config():\n","    \"\"\"Print the current configuration.\"\"\"\n","    print(\"\\nRice Leaf Disease Detection with SSD - Configuration\")\n","    print(\"=\" * 50)\n","    print(f\"Dataset: {DATA_ROOT}\")\n","    print(f\"Model type: {MODEL_TYPE}\")\n","    print(f\"Number of classes: {NUM_CLASSES}\")\n","    print(f\"Device: {DEVICE}\")\n","    print(f\"Batch size: {BATCH_SIZE}\")\n","    print(f\"Learning rate: {LEARNING_RATE}\")\n","    print(f\"Number of epochs: {NUM_EPOCHS}\")\n","    print(\"=\" * 50)"],"metadata":{"id":"2lq4bIaiMQOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile setup.py\n","import os\n","import subprocess\n","import sys\n","from google.colab import drive\n","\n","def mount_drive():\n","    # need to get that data from somewhere\n","    drive.mount('/content/drive')\n","    print(\"Drive mounted successfully!\")\n","\n","def check_gpu():\n","    try:\n","        gpu_info = subprocess.check_output('nvidia-smi', shell=True).decode('utf-8')\n","        print(\"GPU information:\")\n","        print(gpu_info)\n","        return True\n","    except:\n","        print(\"No GPU found or nvidia-smi command failed.\")\n","        return False\n","\n","def check_dataset():\n","    data_dir = \"/content/drive/MyDrive/Coco_Dataset\"\n","    try:\n","        train_dir = os.path.join(data_dir, \"train\")\n","        val_dir = os.path.join(data_dir, \"valid\")\n","        test_dir = os.path.join(data_dir, \"test\")\n","\n","        train_anno = os.path.join(train_dir, \"_annotations.coco.json\")\n","        val_anno = os.path.join(val_dir, \"_annotations.coco.json\")\n","        test_anno = os.path.join(test_dir, \"_annotations.coco.json\")\n","\n","        paths_to_check = [train_dir, val_dir, test_dir, train_anno, val_anno, test_anno]\n","\n","        for path in paths_to_check:\n","            if not os.path.exists(path):\n","                print(f\"Missing path: {path}\")\n","                return False\n","\n","        # Check if there are images in the directories\n","        train_files = [f for f in os.listdir(train_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n","        val_files = [f for f in os.listdir(val_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n","        test_files = [f for f in os.listdir(test_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n","\n","        print(f\"Train images: {len(train_files)}\")\n","        print(f\"Validation images: {len(val_files)}\")\n","        print(f\"Test images: {len(test_files)}\")\n","\n","        if len(train_files) == 0 or len(val_files) == 0 or len(test_files) == 0:\n","            print(\"Warning: One or more directories have no images.\")\n","            return False\n","\n","        print(\"Dataset looks good!\")\n","        return True\n","\n","    except Exception as e:\n","        print(f\"Error checking dataset: {e}\")\n","        return False\n","\n","def install_packages():\n","    packages = [\n","        \"pip install torch torchvision pycocotools\",\n","        \"pip install seaborn scikit-learn matplotlib\"\n","    ]\n","\n","    for cmd in packages:\n","        try:\n","            print(f\"Running: {cmd}\")\n","            subprocess.run(cmd, shell=True, check=True)\n","            print(\"Installation successful\")\n","        except subprocess.CalledProcessError as e:\n","            print(f\"Failed to run: {cmd}\")\n","            print(f\"Error: {e}\")\n","            return False\n","\n","    return True\n","\n","def check_environment():\n","    try:\n","        import torch\n","        import torchvision\n","        from pycocotools.coco import COCO\n","\n","        print(f\"PyTorch version: {torch.__version__}\")\n","        print(f\"CUDA available: {torch.cuda.is_available()}\")\n","        if torch.cuda.is_available():\n","            print(f\"CUDA version: {torch.version.cuda}\")\n","\n","        return True\n","\n","    except ImportError as e:\n","        print(f\"Environment check failed: {e}\")\n","        print(\"Please run setup.install_packages() first.\")\n","        return False\n","\n","def setup_all():\n","    mount_drive()\n","    gpu_ok = check_gpu()\n","    if not gpu_ok:\n","        print(\"Warning: GPU issues detected. Training may be slow.\")\n","\n","    dataset_ok = check_dataset()\n","    if not dataset_ok:\n","        print(\"Warning: Dataset issues detected.\")\n","\n","    packages_ok = install_packages()\n","    if not packages_ok:\n","        print(\"Error installing packages.\")\n","        return False\n","\n","    env_ok = check_environment()\n","    if not env_ok:\n","        print(\"Environment check failed.\")\n","        return False\n","\n","    print(\"Setup completed successfully!\")\n","    return True\n","\n","if __name__ == \"__main__\":\n","    print(\"Setting up Rice Leaf Disease Detection with SSD...\")\n","    setup_all()"],"metadata":{"id":"ZSPr0ctfMcS1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile data.py\n","import torch\n","import json\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from pycocotools.coco import COCO\n","from PIL import Image\n","import numpy as np\n","import os\n","from config import *\n","\n","class RiceLeafDataset(Dataset):\n","    def __init__(self, root, annFile, transform=None, target_transform=None):\n","        self.root = root\n","        self.coco = COCO(annFile)\n","        self.ids = list(self.coco.imgs.keys())\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","        # Load category mapping (needed to remap category IDs if necessary)\n","        with open(annFile, 'r') as f:\n","            data = json.load(f)\n","\n","        # Create a mapping from original category IDs to sequential IDs (0-indexed)\n","        self.cat_mapping = {}\n","        for i, cat in enumerate(data['categories']):\n","            self.cat_mapping[cat['id']] = i + 1  # +1 because 0 is background in SSD\n","\n","        print(f\"Loaded {len(self.ids)} images\")\n","        print(f\"Category mapping: {self.cat_mapping}\")\n","\n","    def __getitem__(self, index):\n","        img_id = self.ids[index]\n","        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n","        annotations = self.coco.loadAnns(ann_ids)\n","\n","        # Load image\n","        img_info = self.coco.loadImgs(img_id)[0]\n","        img_path = os.path.join(self.root, img_info['file_name'])\n","        img = Image.open(img_path).convert('RGB')\n","\n","        # Get image dimensions\n","        width, height = img.size\n","\n","        # Process annotations\n","        boxes = []\n","        labels = []\n","        area = []\n","        iscrowd = []\n","\n","        for ann in annotations:\n","            # Get bbox in [x_min, y_min, width, height] format\n","            x, y, w, h = ann['bbox']\n","\n","            # Skip invalid boxes\n","            if w <= 0 or h <= 0:\n","                continue\n","\n","            # Convert to [x_min, y_min, x_max, y_max] format for PyTorch\n","            boxes.append([x, y, x + w, y + h])\n","\n","            # Get category ID (remap if necessary)\n","            cat_id = ann['category_id']\n","            if cat_id in self.cat_mapping:\n","                # remap category ID\n","                cat_id = self.cat_mapping[cat_id]\n","            labels.append(cat_id)\n","\n","            area.append(ann.get('area', w * h))\n","            iscrowd.append(ann.get('iscrowd', 0))\n","\n","        # Convert to tensors\n","        if boxes:\n","            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n","            labels = torch.as_tensor(labels, dtype=torch.int64)\n","            area = torch.as_tensor(area, dtype=torch.float32)\n","            iscrowd = torch.as_tensor(iscrowd, dtype=torch.int64)\n","        else:\n","            # Handle images with no annotations\n","            boxes = torch.zeros((0, 4), dtype=torch.float32)\n","            labels = torch.zeros(0, dtype=torch.int64)\n","            area = torch.zeros(0, dtype=torch.float32)\n","            iscrowd = torch.zeros(0, dtype=torch.int64)\n","\n","        # Create target dictionary\n","        target = {\n","            'boxes': boxes,\n","            'labels': labels,\n","            'image_id': torch.tensor([img_id]),\n","            'area': area,\n","            'iscrowd': iscrowd\n","        }\n","\n","        # Apply transforms\n","        if self.transform is not None:\n","            img = self.transform(img)\n","\n","        if self.target_transform is not None:\n","            target = self.target_transform(target)\n","\n","        return img, target\n","\n","    def __len__(self):\n","        return len(self.ids)\n","\n","def get_data_transforms():\n","    # Training transforms with augmentation\n","    train_transform = transforms.Compose([\n","        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomRotation(10),\n","        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","\n","    # Validation and test transforms (no augmentation)\n","    val_transform = transforms.Compose([\n","        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","\n","    return train_transform, val_transform\n","\n","def collate_fn(batch):\n","    images = []\n","    targets = []\n","    for img, target in batch:\n","        images.append(img)\n","        targets.append(target)\n","    return images, targets\n","\n","def get_dataloaders():\n","    # Get transforms\n","    train_transform, val_transform = get_data_transforms()\n","\n","    # Create datasets\n","    train_dataset = RiceLeafDataset(root=TRAIN_DIR, annFile=TRAIN_ANNO, transform=train_transform)\n","    val_dataset = RiceLeafDataset(root=VAL_DIR, annFile=VAL_ANNO, transform=val_transform)\n","    test_dataset = RiceLeafDataset(root=TEST_DIR, annFile=TEST_ANNO, transform=val_transform)\n","\n","    # Create DataLoaders\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True,\n","        num_workers=NUM_WORKERS,\n","        collate_fn=collate_fn,\n","        pin_memory=True\n","    )\n","\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=BATCH_SIZE,\n","        shuffle=False,\n","        num_workers=NUM_WORKERS,\n","        collate_fn=collate_fn,\n","        pin_memory=True\n","    )\n","\n","    test_loader = DataLoader(\n","        test_dataset,\n","        batch_size=BATCH_SIZE,\n","        shuffle=False,\n","        num_workers=NUM_WORKERS,\n","        collate_fn=collate_fn,\n","        pin_memory=True\n","    )\n","\n","    print(f\"Train dataset: {len(train_dataset)} images\")\n","    print(f\"Validation dataset: {len(val_dataset)} images\")\n","    print(f\"Test dataset: {len(test_dataset)} images\")\n","\n","    return train_loader, val_loader, test_loader\n","\n","def get_class_weights(train_loader):\n","    class_counts = torch.zeros(NUM_CLASSES)\n","\n","    for _, targets in train_loader:\n","        for target in targets:\n","            labels = target['labels']\n","            for label in labels:\n","                class_counts[label] += 1\n","\n","    # Add a small constant to avoid division by zero\n","    class_counts = class_counts + 1e-6\n","\n","    # Inverse frequency weighting\n","    class_weights = 1.0 / class_counts\n","\n","    # Normalize weights to sum to NUM_CLASSES\n","    class_weights = class_weights * (NUM_CLASSES / class_weights.sum())\n","\n","    print(\"Class weights:\")\n","    for i, weight in enumerate(class_weights):\n","        if i < len(CLASS_NAMES):\n","            print(f\"  {CLASS_NAMES[i]}: {weight.item():.4f}\")\n","        else:\n","            print(f\"  Class {i}: {weight.item():.4f}\")\n","\n","    return class_weights.to(DEVICE)\n","\n","def analyze_dataset():\n","    \"\"\"\n","    Analyze the dataset to get statistics about classes, box sizes, etc.\n","    \"\"\"\n","    datasets = [\n","        ('Training', TRAIN_ANNO),\n","        ('Validation', VAL_ANNO),\n","        ('Testing', TEST_ANNO)\n","    ]\n","\n","    for name, annFile in datasets:\n","        print(f\"\\n{name} Dataset Analysis:\")\n","        coco = COCO(annFile)\n","\n","        # Number of images\n","        img_ids = coco.getImgIds()\n","        print(f\"Number of images: {len(img_ids)}\")\n","\n","        # Number of instances per category\n","        cat_ids = coco.getCatIds()\n","        print(f\"Categories: {cat_ids}\")\n","\n","        for cat_id in cat_ids:\n","            cat_name = coco.loadCats(cat_id)[0]['name']\n","            ann_ids = coco.getAnnIds(catIds=cat_id)\n","            print(f\"  {cat_name} (ID: {cat_id}): {len(ann_ids)} instances\")\n","\n","        # Box size distribution\n","        all_anns = coco.loadAnns(coco.getAnnIds())\n","        areas = [ann['area'] for ann in all_anns]\n","\n","        if areas:\n","            min_area = min(areas)\n","            max_area = max(areas)\n","            avg_area = sum(areas) / len(areas)\n","\n","            print(f\"Bounding box areas:\")\n","            print(f\"  Min: {min_area:.2f} pixels²\")\n","            print(f\"  Max: {max_area:.2f} pixels²\")\n","            print(f\"  Avg: {avg_area:.2f} pixels²\")\n","        else:\n","            print(\"No annotations found.\")\n","\n","if __name__ == \"__main__\":\n","    # If run directly, analyze the dataset\n","    analyze_dataset()\n","\n","    # Test the data loading\n","    print(\"\\nTesting data loading...\")\n","    train_loader, val_loader, test_loader = get_dataloaders()\n","\n","    # Display a few samples from the training set\n","    for images, targets in train_loader:\n","        print(f\"Batch size: {len(images)}\")\n","        print(f\"Image shape: {images[0].shape}\")\n","        print(f\"Target example: {targets[0]}\")\n","        break"],"metadata":{"id":"GwMfbvvXMis4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile model.py\n","import torch\n","import torch.nn as nn\n","from torchvision.models.detection import ssd300_vgg16\n","from torchvision.models.detection.ssd import SSDHead\n","import torchvision\n","import os\n","from config import *\n","\n","def get_model(num_classes=NUM_CLASSES, pretrained=True):\n","    print(f\"Creating {MODEL_TYPE} model with {num_classes} classes...\")\n","\n","    # Load the pretrained model\n","    model = ssd300_vgg16(pretrained=pretrained)\n","\n","    # Modify the classification head for the new number of classes\n","    # SSD has one classification head per feature map\n","    in_channels = model.head.classification_head.classification_headers[0].in_channels\n","    num_anchors = model.head.classification_head.classification_headers[0].out_channels // 21  # 21 is the default num_classes (20 + background)\n","\n","    # Create new classification headers for our number of classes\n","    classification_headers = nn.ModuleList([\n","        nn.Conv2d(in_channels, num_anchors * num_classes, kernel_size=3, padding=1)\n","        for in_channels in model.head.classification_head.in_channels\n","    ])\n","\n","    # Replace the classification heads in the model\n","    model.head.classification_head.classification_headers = classification_headers\n","    model.head.classification_head.num_classes = num_classes\n","\n","    # Move model to the correct device\n","    model.to(DEVICE)\n","\n","    print(f\"Model created and moved to {DEVICE}\")\n","    return model\n","\n","def save_model(model, path=MODEL_SAVE_PATH):\n","    # Create directory if it doesn't exist\n","    os.makedirs(os.path.dirname(path), exist_ok=True)\n","\n","    # Save the model\n","    torch.save({\n","        'model_state_dict': model.state_dict(),\n","        'num_classes': NUM_CLASSES,\n","        'model_type': MODEL_TYPE\n","    }, path)\n","\n","    print(f\"Model saved to {path}\")\n","\n","def load_model(path=MODEL_SAVE_PATH):\n","    if not os.path.exists(path):\n","        print(f\"Model file not found at {path}\")\n","        return None\n","\n","    # Load the saved model info\n","    checkpoint = torch.load(path, map_location=DEVICE)\n","\n","    # Create a new model with the same configuration\n","    model = get_model(num_classes=checkpoint.get('num_classes', NUM_CLASSES), pretrained=False)\n","\n","    # Load the state dictionary\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","\n","    print(f\"Model loaded from {path}\")\n","    return model\n","\n","def get_model_summary(model):\n","    # Need to use torchinfo for better summary if available\n","    try:\n","        from torchinfo import summary\n","        model_summary = summary(model, input_size=(BATCH_SIZE, 3, IMAGE_SIZE, IMAGE_SIZE),\n","                               verbose=0, device=DEVICE)\n","        return str(model_summary)\n","    except ImportError:\n","        return str(model)\n","\n","def test_model():\n","    # Create a model\n","    model = get_model()\n","    model.eval()\n","\n","    # Create a dummy input\n","    dummy_input = torch.randn(2, 3, IMAGE_SIZE, IMAGE_SIZE).to(DEVICE)\n","\n","    # Test in training mode (requires targets)\n","    model.train()\n","    dummy_target = [\n","        {\n","            'boxes': torch.tensor([[10, 10, 100, 100]], dtype=torch.float32).to(DEVICE),\n","            'labels': torch.tensor([1], dtype=torch.int64).to(DEVICE)\n","        },\n","        {\n","            'boxes': torch.tensor([[50, 50, 150, 150]], dtype=torch.float32).to(DEVICE),\n","            'labels': torch.tensor([2], dtype=torch.int64).to(DEVICE)\n","        }\n","    ]\n","\n","    try:\n","        loss_dict = model(dummy_input, dummy_target)\n","        print(\"Model training mode test successful\")\n","        print(f\"Loss dictionary: {loss_dict}\")\n","    except Exception as e:\n","        print(f\"Model training mode test failed: {e}\")\n","\n","    # Test in evaluation mode\n","    model.eval()\n","    with torch.no_grad():\n","        try:\n","            predictions = model(dummy_input)\n","            print(\"\\nModel evaluation mode test successful\")\n","            print(f\"Predictions: {len(predictions)} items\")\n","\n","            # Print the keys in the first prediction\n","            print(f\"Prediction keys: {predictions[0].keys()}\")\n","\n","            # Check shapes\n","            print(f\"Boxes shape: {predictions[0]['boxes'].shape}\")\n","            print(f\"Labels shape: {predictions[0]['labels'].shape}\")\n","            print(f\"Scores shape: {predictions[0]['scores'].shape}\")\n","\n","        except Exception as e:\n","            print(f\"Model evaluation mode test failed: {e}\")\n","\n","    return model\n","\n","if __name__ == \"__main__\":\n","    # Test the model\n","    model = test_model()\n","\n","    # Print model summary\n","    print(\"\\nModel Architecture:\")\n","    print(get_model_summary(model))"],"metadata":{"id":"PjcaLiJ5MnCH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile train.py\n","import torch\n","import time\n","import datetime\n","import os\n","from torch.cuda.amp import GradScaler, autocast\n","from torch.optim.lr_scheduler import StepLR\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from model import get_model, save_model\n","from data import get_dataloaders, get_class_weights\n","from config import *\n","\n","def train_one_epoch(model, dataloader, optimizer, scaler, device, epoch):\n","    model.train()\n","    total_loss = 0\n","    loss_classifier = 0\n","    loss_box_reg = 0\n","    loss_objectness = 0\n","    loss_rpn_box_reg = 0\n","\n","    # Progress tracking\n","    start_time = time.time()\n","    num_batches = len(dataloader)\n","    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}: Training...\")\n","\n","    for i, (images, targets) in enumerate(dataloader):\n","        # Move data to device\n","        images = [img.to(device) for img in images]\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass with mixed precision\n","        with autocast(device_type='cuda' if device.type == 'cuda' else 'cpu'):\n","            loss_dict = model(images, targets)\n","            # Calculate total loss\n","            losses = sum(loss for loss in loss_dict.values())\n","\n","        # Backward pass with gradient scaling\n","        scaler.scale(losses).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        # Add to running loss\n","        total_loss += losses.item()\n","\n","        # Track individual losses\n","        for loss_name, loss_value in loss_dict.items():\n","            if 'classifier' in loss_name:\n","                loss_classifier += loss_value.item()\n","            elif 'box_reg' in loss_name and 'rpn' not in loss_name:\n","                loss_box_reg += loss_value.item()\n","            elif 'objectness' in loss_name:\n","                loss_objectness += loss_value.item()\n","            elif 'rpn_box_reg' in loss_name:\n","                loss_rpn_box_reg += loss_value.item()\n","\n","        # Print progress\n","        if (i + 1) % 10 == 0 or (i + 1) == num_batches:\n","            elapsed = time.time() - start_time\n","            elapsed_str = str(datetime.timedelta(seconds=int(elapsed)))\n","            eta = elapsed * (num_batches - i - 1) / (i + 1)\n","            eta_str = str(datetime.timedelta(seconds=int(eta)))\n","            print(f\"  Batch {i+1}/{num_batches}, Loss: {losses.item():.4f}, Time: {elapsed_str}, ETA: {eta_str}\", end='\\r')\n","\n","    # Calculate average losses\n","    avg_loss = total_loss / num_batches\n","    avg_loss_classifier = loss_classifier / num_batches\n","    avg_loss_box_reg = loss_box_reg / num_batches\n","    avg_loss_objectness = loss_objectness / num_batches\n","    avg_loss_rpn_box_reg = loss_rpn_box_reg / num_batches\n","\n","    print(f\"\\nEpoch {epoch+1}: Avg Loss: {avg_loss:.4f}, Classifier: {avg_loss_classifier:.4f}, \"\n","          f\"Box Reg: {avg_loss_box_reg:.4f}, Objectness: {avg_loss_objectness:.4f}, \"\n","          f\"RPN Box Reg: {avg_loss_rpn_box_reg:.4f}\")\n","\n","    return {\n","        'total': avg_loss,\n","        'classifier': avg_loss_classifier,\n","        'box_reg': avg_loss_box_reg,\n","        'objectness': avg_loss_objectness,\n","        'rpn_box_reg': avg_loss_rpn_box_reg\n","    }\n","\n","def validate(model, dataloader, device, epoch):\n","    model.eval()\n","    total_loss = 0\n","    loss_classifier = 0\n","    loss_box_reg = 0\n","    loss_objectness = 0\n","    loss_rpn_box_reg = 0\n","\n","    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}: Validating...\")\n","\n","    with torch.no_grad():\n","        for i, (images, targets) in enumerate(dataloader):\n","            # Move data to device\n","            images = [img.to(device) for img in images]\n","            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","            # Forward pass (don't need mixed precision for validation)\n","            loss_dict = model(images, targets)\n","\n","            # Calculate total loss\n","            losses = sum(loss for loss in loss_dict.values())\n","\n","            # Add to running loss\n","            total_loss += losses.item()\n","\n","            # Track individual losses\n","            for loss_name, loss_value in loss_dict.items():\n","                if 'classifier' in loss_name:\n","                    loss_classifier += loss_value.item()\n","                elif 'box_reg' in loss_name and 'rpn' not in loss_name:\n","                    loss_box_reg += loss_value.item()\n","                elif 'objectness' in loss_name:\n","                    loss_objectness += loss_value.item()\n","                elif 'rpn_box_reg' in loss_name:\n","                    loss_rpn_box_reg += loss_value.item()\n","\n","    # Calculate average losses\n","    num_batches = len(dataloader)\n","    avg_loss = total_loss / num_batches\n","    avg_loss_classifier = loss_classifier / num_batches\n","    avg_loss_box_reg = loss_box_reg / num_batches\n","    avg_loss_objectness = loss_objectness / num_batches\n","    avg_loss_rpn_box_reg = loss_rpn_box_reg / num_batches\n","\n","    print(f\"Validation Loss: {avg_loss:.4f}, Classifier: {avg_loss_classifier:.4f}, \"\n","          f\"Box Reg: {avg_loss_box_reg:.4f}, Objectness: {avg_loss_objectness:.4f}, \"\n","          f\"RPN Box Reg: {avg_loss_rpn_box_reg:.4f}\")\n","\n","    return {\n","        'total': avg_loss,\n","        'classifier': avg_loss_classifier,\n","        'box_reg': avg_loss_box_reg,\n","        'objectness': avg_loss_objectness,\n","        'rpn_box_reg': avg_loss_rpn_box_reg\n","    }\n","\n","def plot_losses(train_losses, val_losses, save_path=None):\n","    plt.figure(figsize=(12, 8))\n","    epochs = range(1, len(train_losses) + 1)\n","\n","    # Plot total loss\n","    plt.subplot(2, 2, 1)\n","    plt.plot(epochs, [loss['total'] for loss in train_losses], 'b-', label='Training Loss')\n","    plt.plot(epochs, [loss['total'] for loss in val_losses], 'r-', label='Validation Loss')\n","    plt.title('Total Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.grid(True)\n","\n","    # Plot classifier loss\n","    plt.subplot(2, 2, 2)\n","    plt.plot(epochs, [loss['classifier'] for loss in train_losses], 'b-', label='Training')\n","    plt.plot(epochs, [loss['classifier'] for loss in val_losses], 'r-', label='Validation')\n","    plt.title('Classifier Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.grid(True)\n","\n","    # Plot box regression loss\n","    plt.subplot(2, 2, 3)\n","    plt.plot(epochs, [loss['box_reg'] for loss in train_losses], 'b-', label='Training')\n","    plt.plot(epochs, [loss['box_reg'] for loss in val_losses], 'r-', label='Validation')\n","    plt.title('Box Regression Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.grid(True)\n","\n","    # Plot objectness loss\n","    plt.subplot(2, 2, 4)\n","    plt.plot(epochs, [loss['objectness'] for loss in train_losses], 'b-', label='Training')\n","    plt.plot(epochs, [loss['objectness'] for loss in val_losses], 'r-', label='Validation')\n","    plt.title('Objectness Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.grid(True)\n","\n","    plt.tight_layout()\n","\n","    if save_path:\n","        plt.savefig(save_path)\n","        print(f\"Loss plot saved to {save_path}\")\n","    else:\n","        plt.show()\n","\n","    plt.close()\n","\n","def train_model(resume_from=None):\n","    \"\"\"\n","    Train the SSD model.\n","\n","    Args:\n","        resume_from: Path to saved model to resume training from (if None, start fresh)\n","\n","    Returns:\n","        Trained model and loss history\n","    \"\"\"\n","    # Get data loaders\n","    train_loader, val_loader, _ = get_dataloaders()\n","\n","    # Get model\n","    if resume_from and os.path.exists(resume_from):\n","        # Load the model to resume training\n","        from model import load_model\n","        model = load_model(resume_from)\n","        print(f\"Resuming training from {resume_from}\")\n","    else:\n","        # Create a new model\n","        model = get_model(num_classes=NUM_CLASSES, pretrained=True)\n","        print(\"Starting fresh training\")\n","\n","    # Define optimizer\n","    optimizer = torch.optim.SGD(\n","        model.parameters(),\n","        lr=LEARNING_RATE,\n","        momentum=MOMENTUM,\n","        weight_decay=WEIGHT_DECAY\n","    )\n","\n","    # Learning rate scheduler\n","    scheduler = StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n","\n","    # Create gradient scaler for mixed precision training\n","    scaler = GradScaler(enabled=(DEVICE.type == 'cuda'))\n","\n","    # Lists to store losses\n","    train_losses = []\n","    val_losses = []\n","    best_val_loss = float('inf')\n","\n","    # Start timer\n","    start_time = time.time()\n","\n","    # Train for the specified number of epochs\n","    for epoch in range(NUM_EPOCHS):\n","        # Train for one epoch\n","        train_loss = train_one_epoch(model, train_loader, optimizer, scaler, DEVICE, epoch)\n","        train_losses.append(train_loss)\n","\n","        # Validate\n","        val_loss = validate(model, val_loader, DEVICE, epoch)\n","        val_losses.append(val_loss)\n","\n","        # Update learning rate\n","        scheduler.step()\n","\n","        # Save model if validation loss improved\n","        if val_loss['total'] < best_val_loss:\n","            best_val_loss = val_loss['total']\n","            save_model(model, os.path.join(OUTPUT_DIR, \"best_model.pth\"))\n","            print(f\"Saved best model with validation loss: {best_val_loss:.4f}\")\n","\n","        # Save checkpoint every 10 epochs\n","        if (epoch + 1) % 10 == 0:\n","            save_model(model, os.path.join(OUTPUT_DIR, f\"checkpoint_epoch{epoch+1}.pth\"))\n","\n","            # Plot and save losses so far\n","            plot_losses(train_losses, val_losses,\n","                       save_path=os.path.join(METRICS_SAVE_PATH, f\"losses_epoch{epoch+1}.png\"))\n","\n","    # Calculate training time\n","    total_time = time.time() - start_time\n","    print(f\"Training completed in {datetime.timedelta(seconds=int(total_time))}\")\n","\n","    # Save final model\n","    save_model(model)\n","    print(f\"Saved final model to {MODEL_SAVE_PATH}\")\n","\n","    # Plot losses\n","    plot_losses(train_losses, val_losses,\n","               save_path=os.path.join(METRICS_SAVE_PATH, \"losses_final.png\"))\n","\n","    return model, (train_losses, val_losses)\n","\n","if __name__ == \"__main__\":\n","    # Train the model\n","    model, losses = train_model()"],"metadata":{"id":"XfmmqpVqMsB4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile utils.py\n","import os\n","import torch\n","import numpy as np\n","import json\n","import matplotlib.pyplot as plt\n","from torchvision.ops import box_iou\n","from config import *\n","\n","def calculate_map(pred_boxes, pred_labels, pred_scores, gt_boxes, gt_labels, iou_threshold=0.5, num_classes=NUM_CLASSES):\n","    # If no predictions or ground truth, return 0\n","    if len(pred_boxes) == 0 or len(gt_boxes) == 0:\n","        return 0.0, {cls: 0.0 for cls in range(1, num_classes)}\n","\n","    # Convert to tensors if not already\n","    if not isinstance(pred_boxes, torch.Tensor):\n","        pred_boxes = torch.tensor(pred_boxes, dtype=torch.float32)\n","        pred_labels = torch.tensor(pred_labels, dtype=torch.int64)\n","        pred_scores = torch.tensor(pred_scores, dtype=torch.float32)\n","        gt_boxes = torch.tensor(gt_boxes, dtype=torch.float32)\n","        gt_labels = torch.tensor(gt_labels, dtype=torch.int64)\n","\n","    # Calculate IoU matrix between all predictions and ground truth boxes\n","    iou_matrix = box_iou(pred_boxes, gt_boxes)\n","\n","    # Calculate AP for each class\n","    aps = {}\n","    for cls in range(1, num_classes):  # Skip background class\n","        # Find predictions and ground truth for this class\n","        cls_pred_indices = (pred_labels == cls).nonzero(as_tuple=True)[0]\n","        cls_gt_indices = (gt_labels == cls).nonzero(as_tuple=True)[0]\n","\n","        # If no predictions or ground truth for this class, AP is 0\n","        if len(cls_pred_indices) == 0 or len(cls_gt_indices) == 0:\n","            aps[cls] = 0.0\n","            continue\n","\n","        # Get scores for this class\n","        cls_scores = pred_scores[cls_pred_indices]\n","\n","        # Sort predictions by confidence score (descending)\n","        sorted_indices = torch.argsort(cls_scores, descending=True)\n","        cls_pred_indices = cls_pred_indices[sorted_indices]\n","\n","        # Get IoU matrix for this class\n","        cls_iou_matrix = iou_matrix[cls_pred_indices][:, cls_gt_indices]\n","\n","        # For each prediction, find the best matching ground truth\n","        tp = torch.zeros(len(cls_pred_indices))\n","        fp = torch.zeros(len(cls_pred_indices))\n","\n","        # Keep track of which ground truths have been matched\n","        gt_matched = torch.zeros(len(cls_gt_indices), dtype=torch.bool)\n","\n","        # For each prediction (in order of confidence)\n","        for i in range(len(cls_pred_indices)):\n","            # Find the ground truth with highest IoU\n","            max_iou, max_idx = torch.max(cls_iou_matrix[i], dim=0)\n","\n","            # If IoU > threshold and ground truth not already matched, it's a true positive\n","            if max_iou >= iou_threshold and not gt_matched[max_idx]:\n","                tp[i] = 1\n","                gt_matched[max_idx] = True\n","            else:\n","                fp[i] = 1\n","\n","        # Calculate precision and recall at each prediction\n","        tp_cumsum = torch.cumsum(tp, dim=0)\n","        fp_cumsum = torch.cumsum(fp, dim=0)\n","\n","        precision = tp_cumsum / (tp_cumsum + fp_cumsum)\n","        recall = tp_cumsum / len(cls_gt_indices)\n","\n","        # Append sentinel values for easier calculation\n","        precision = torch.cat([torch.tensor([1.0]), precision])\n","        recall = torch.cat([torch.tensor([0.0]), recall])\n","\n","        # Calculate AP using all points interpolation\n","        # For each recall level, take the maximum precision\n","        for i in range(len(precision) - 2, -1, -1):\n","            precision[i] = max(precision[i], precision[i + 1])\n","\n","        # Calculate area under the curve (AP)\n","        ap = 0.0\n","        for i in range(1, len(recall)):\n","            ap += (recall[i] - recall[i - 1]) * precision[i]\n","\n","        aps[cls] = float(ap)\n","\n","    # Calculate mAP\n","    map_value = sum(aps.values()) / (num_classes - 1)  # Exclude background\n","\n","    return map_value, aps\n","\n","def plot_image_with_boxes(image, boxes, labels, scores=None, class_names=None, figsize=(10, 10), title=None):\n","    # Convert tensor to numpy array if needed\n","    if isinstance(image, torch.Tensor):\n","        image = image.permute(1, 2, 0).cpu().numpy()\n","        # Denormalize if needed\n","        image = image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n","        image = np.clip(image, 0, 1)\n","\n","    # Create figure and axes\n","    fig, ax = plt.subplots(1, figsize=figsize)\n","    ax.imshow(image)\n","\n","    # Colors for different classes\n","    colors = plt.cm.hsv(np.linspace(0, 1, NUM_CLASSES))\n","\n","    # Draw each box\n","    for i, (box, label) in enumerate(zip(boxes, labels)):\n","        # Get box coordinates\n","        x1, y1, x2, y2 = box\n","\n","        # Create rectangle\n","        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,\n","                           edgecolor=colors[label % len(colors)], facecolor='none')\n","        ax.add_patch(rect)\n","\n","        # Add label text\n","        class_name = class_names[label] if class_names and label < len(class_names) else f\"Class {label}\"\n","        text = class_name\n","\n","        # Add score if provided\n","        if scores is not None:\n","            text += f\": {scores[i]:.2f}\"\n","\n","        # Draw label\n","        ax.text(x1, y1, text, backgroundcolor=colors[label % len(colors)], color='white', fontsize=8)\n","\n","    # Add title if provided\n","    if title:\n","        ax.set_title(title)\n","\n","    # Remove axes ticks\n","    ax.set_xticks([])\n","    ax.set_yticks([])\n","\n","    # Show the plot\n","    plt.tight_layout()\n","    plt.show()\n","\n","def save_model_info(model, losses, metrics, output_dir=None):\n","    if output_dir is None:\n","        output_dir = METRICS_SAVE_PATH\n","\n","    # Create directory if it doesn't exist\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Save model architecture summary\n","    try:\n","        from model import get_model_summary\n","        model_summary = get_model_summary(model)\n","\n","        with open(os.path.join(output_dir, \"model_summary.txt\"), \"w\") as f:\n","            f.write(model_summary)\n","    except Exception as e:\n","        print(f\"Failed to save model summary: {e}\")\n","\n","    # Save losses\n","    if losses:\n","        try:\n","            train_losses, val_losses = losses\n","\n","            # Convert to serializable format\n","            train_losses_json = []\n","            for loss in train_losses:\n","                train_losses_json.append({k: float(v) for k, v in loss.items()})\n","\n","            val_losses_json = []\n","            for loss in val_losses:\n","                val_losses_json.append({k: float(v) for k, v in loss.items()})\n","\n","            with open(os.path.join(output_dir, \"training_losses.json\"), \"w\") as f:\n","                json.dump({\"train\": train_losses_json, \"val\": val_losses_json}, f, indent=4)\n","        except Exception as e:\n","            print(f\"Failed to save losses: {e}\")\n","\n","    # Save metrics\n","    if metrics:\n","        try:\n","            with open(os.path.join(output_dir, \"evaluation_metrics.json\"), \"w\") as f:\n","                json.dump(metrics, f, indent=4)\n","        except Exception as e:\n","            print(f\"Failed to save metrics: {e}\")\n","\n","def check_dataset_balance(coco_json_path):\n","    # Load the JSON file\n","    with open(coco_json_path, \"r\") as f:\n","        data = json.load(f)\n","\n","    # Get categories and their IDs\n","    categories = {}\n","    for cat in data[\"categories\"]:\n","        categories[cat[\"id\"]] = cat[\"name\"]\n","\n","    # Count annotations by category\n","    class_counts = {cat_id: 0 for cat_id in categories}\n","\n","    for ann in data[\"annotations\"]:\n","        cat_id = ann[\"category_id\"]\n","        if cat_id in class_counts:\n","            class_counts[cat_id] += 1\n","\n","    # Print class counts\n","    print(f\"Class distribution in {os.path.basename(coco_json_path)}:\")\n","    for cat_id, count in class_counts.items():\n","        cat_name = categories[cat_id]\n","        print(f\"  - {cat_name} (ID: {cat_id}): {count}\")\n","\n","    # Calculate class imbalance\n","    total_annotations = sum(class_counts.values())\n","    max_count = max(class_counts.values())\n","    min_count = min(class_counts.values())\n","\n","    print(f\"Total annotations: {total_annotations}\")\n","    print(f\"Max/min ratio: {max_count/min_count:.2f}\")\n","\n","    # Return the counts\n","    return class_counts\n","\n","def model_complexity(model):\n","    # Calculate number of parameters\n","    total_params = sum(p.numel() for p in model.parameters())\n","    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","    # Print parameter counts\n","    print(f\"Total parameters: {total_params:,}\")\n","    print(f\"Trainable parameters: {trainable_params:,}\")\n","    print(f\"Non-trainable parameters: {total_params - trainable_params:,}\")\n","\n","    # Calculate FLOPs if torchprofile is available\n","    flops = None\n","    try:\n","        from torchprofile import profile_macs\n","        dummy_input = torch.randn(1, 3, IMAGE_SIZE, IMAGE_SIZE).to(next(model.parameters()).device)\n","        flops = profile_macs(model, dummy_input)\n","        print(f\"Estimated FLOPs: {flops:,}\")\n","    except ImportError:\n","        print(\"torchprofile not installed. FLOPs calculation skipped.\")\n","\n","    return {\n","        \"total_params\": total_params,\n","        \"trainable_params\": trainable_params,\n","        \"non_trainable_params\": total_params - trainable_params,\n","        \"flops\": flops\n","    }\n","\n","if __name__ == \"__main__\":\n","    # Print header\n","    print(\"Rice Leaf Disease Detection with SSD - Utilities\")\n","\n","    # Check dataset balance\n","    for json_path in [TRAIN_ANNO, VAL_ANNO, TEST_ANNO]:\n","        if os.path.exists(json_path):\n","            check_dataset_balance(json_path)\n","            print()"],"metadata":{"id":"kFsFllYxNpzb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile visualize.py\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","from PIL import Image, ImageDraw, ImageFont\n","import cv2\n","import os\n","import random\n","from torchvision import transforms\n","from torch.cuda.amp import autocast\n","\n","from model import load_model\n","from data import RiceLeafDataset\n","from config import *\n","\n","def visualize_dataset_samples(dataset, num_samples=5, output_dir=None):\n","    # Create output directory if it doesn't exist\n","    if output_dir:\n","        os.makedirs(output_dir, exist_ok=True)\n","\n","    # Select random indices\n","    indices = random.sample(range(len(dataset)), min(num_samples, len(dataset)))\n","\n","    for i, idx in enumerate(indices):\n","        # Get image and target\n","        img, target = dataset[idx]\n","\n","        # If it's a tensor, convert to numpy array\n","        if isinstance(img, torch.Tensor):\n","            # Denormalize and convert to numpy array\n","            img = img.permute(1, 2, 0).numpy()\n","            img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n","            img = np.clip(img, 0, 1)\n","\n","        # Create figure\n","        fig, ax = plt.subplots(1, figsize=(12, 9))\n","        ax.imshow(img)\n","\n","        # Extract boxes and labels\n","        boxes = target['boxes'].numpy() if isinstance(target['boxes'], torch.Tensor) else target['boxes']\n","        labels = target['labels'].numpy() if isinstance(target['labels'], torch.Tensor) else target['labels']\n","\n","        # Draw boxes and labels\n","        for box, label in zip(boxes, labels):\n","            x1, y1, x2, y2 = box\n","            width = x2 - x1\n","            height = y2 - y1\n","\n","            # Create rectangle\n","            rect = patches.Rectangle((x1, y1), width, height, linewidth=2, edgecolor='r', facecolor='none')\n","            ax.add_patch(rect)\n","\n","            # Add label\n","            class_name = CLASS_NAMES[label] if label < len(CLASS_NAMES) else f\"Class {label}\"\n","            ax.text(x1, y1, class_name, backgroundcolor='red', color='white', fontsize=8)\n","\n","        # Set title\n","        ax.set_title(f\"Sample {i+1}: {len(boxes)} annotations\")\n","\n","        # Remove axes ticks\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","\n","        # Save or show\n","        if output_dir:\n","            plt.savefig(os.path.join(output_dir, f\"sample_{i+1}.png\"))\n","            plt.close()\n","        else:\n","            plt.show()\n","\n","def visualize_prediction(model, image_path, confidence_threshold=CONFIDENCE_THRESHOLD, output_path=None):\n","    # Set model to evaluation mode\n","    model.eval()\n","    device = next(model.parameters()).device\n","\n","    # Load and preprocess image\n","    image = Image.open(image_path).convert('RGB')\n","    orig_image = image.copy()\n","\n","    # Transform image\n","    transform = transforms.Compose([\n","        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","\n","    input_image = transform(image).unsqueeze(0).to(device)\n","\n","    # Get predictions\n","    with torch.no_grad():\n","        with autocast(device_type='cuda' if device.type == 'cuda' else 'cpu'):\n","            predictions = model(input_image)[0]\n","\n","    # Get boxes, scores, and labels\n","    boxes = predictions['boxes'].cpu().numpy()\n","    scores = predictions['scores'].cpu().numpy()\n","    labels = predictions['labels'].cpu().numpy()\n","\n","    # Filter by confidence threshold\n","    keep = scores >= confidence_threshold\n","    boxes = boxes[keep]\n","    scores = scores[keep]\n","    labels = labels[keep]\n","\n","    # Get original image size\n","    orig_width, orig_height = orig_image.size\n","\n","    # Scale boxes to original image size\n","    scale_x = orig_width / IMAGE_SIZE\n","    scale_y = orig_height / IMAGE_SIZE\n","\n","    scaled_boxes = []\n","    for box in boxes:\n","        x1, y1, x2, y2 = box\n","        scaled_boxes.append([\n","            x1 * scale_x, y1 * scale_y,\n","            x2 * scale_x, y2 * scale_y\n","        ])\n","\n","    boxes = np.array(scaled_boxes)\n","\n","    # Create a copy of the original image for drawing\n","    draw_image = orig_image.copy()\n","    draw = ImageDraw.Draw(draw_image)\n","\n","    # Try to load a font, use default if not available\n","    try:\n","        font = ImageFont.truetype(\"arial.ttf\", 15)\n","    except IOError:\n","        font = ImageFont.load_default()\n","\n","    # Colors for each class\n","    colors = [\n","        (255, 0, 0),    # Red\n","        (0, 255, 0),    # Green\n","        (0, 0, 255),    # Blue\n","        (255, 255, 0),  # Yellow\n","        (255, 0, 255),  # Magenta\n","    ]\n","\n","    # Draw boxes and labels\n","    for i, (box, score, label) in enumerate(zip(boxes, scores, labels)):\n","        x1, y1, x2, y2 = box\n","        color = colors[label % len(colors)]\n","\n","        # Draw box\n","        draw.rectangle([x1, y1, x2, y2], outline=color, width=3)\n","\n","        # Draw label\n","        class_name = CLASS_NAMES[label] if label < len(CLASS_NAMES) else f\"Class {label}\"\n","        text = f\"{class_name}: {score:.2f}\"\n","        text_size = draw.textbbox((0, 0), text, font=font)[2:4]\n","\n","        # Draw text background\n","        draw.rectangle([x1, y1, x1 + text_size[0], y1 + text_size[1]], fill=color)\n","\n","        # Draw text\n","        draw.text((x1, y1), text, fill=(255, 255, 255), font=font)\n","\n","    # Save or show\n","    if output_path:\n","        draw_image.save(output_path)\n","        print(f\"Saved visualization to {output_path}\")\n","    else:\n","        plt.figure(figsize=(12, 9))\n","        plt.imshow(np.array(draw_image))\n","        plt.axis('off')\n","        plt.title(f\"Detection Results: {len(boxes)} objects\")\n","        plt.show()\n","\n","    return draw_image\n","\n","def visualize_batch_predictions(model, dataloader, num_samples=5, confidence_threshold=CONFIDENCE_THRESHOLD, output_dir=None):\n","    # Set model to evaluation mode\n","    model.eval()\n","    device = next(model.parameters()).device\n","\n","    # Create output directory if it doesn't exist\n","    if output_dir:\n","        os.makedirs(output_dir, exist_ok=True)\n","\n","    # Colors for each class\n","    colors = [\n","        (255, 0, 0),    # Red\n","        (0, 255, 0),    # Green\n","        (0, 0, 255),    # Blue\n","        (255, 255, 0),  # Yellow\n","        (255, 0, 255),  # Magenta\n","    ]\n","\n","    # Sample counter\n","    count = 0\n","\n","    # Process batches\n","    for images, targets in dataloader:\n","        # Move images to device\n","        images = [img.to(device) for img in images]\n","\n","        # Get predictions\n","        with torch.no_grad():\n","            with autocast(device_type='cuda' if device.type == 'cuda' else 'cpu'):\n","                predictions = model(images)\n","\n","        # Visualize each image in the batch\n","        for img, target, pred in zip(images, targets, predictions):\n","            # Skip if we've visualized enough samples\n","            if count >= num_samples:\n","                break\n","\n","            # Create figure\n","            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n","\n","            # Denormalize image\n","            img_np = img.cpu().permute(1, 2, 0).numpy()\n","            img_np = img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n","            img_np = np.clip(img_np, 0, 1)\n","\n","            # Show original image with ground truth on the left\n","            ax1.imshow(img_np)\n","            ax1.set_title(\"Ground Truth\")\n","\n","            # Draw ground truth boxes\n","            gt_boxes = target['boxes'].cpu().numpy()\n","            gt_labels = target['labels'].cpu().numpy()\n","\n","            for box, label in zip(gt_boxes, gt_labels):\n","                x1, y1, x2, y2 = box\n","                width = x2 - x1\n","                height = y2 - y1\n","\n","                # Get color for this class\n","                color = colors[label % len(colors)]\n","                color_rgb = [c/255 for c in color]  # Convert to RGB [0,1]\n","\n","                # Create rectangle\n","                rect = patches.Rectangle((x1, y1), width, height, linewidth=2, edgecolor=color_rgb, facecolor='none')\n","                ax1.add_patch(rect)\n","\n","                # Add label\n","                class_name = CLASS_NAMES[label] if label < len(CLASS_NAMES) else f\"Class {label}\"\n","                ax1.text(x1, y1, class_name, backgroundcolor=color_rgb, color='white', fontsize=8)\n","\n","            # Show image with predictions on the right\n","            ax2.imshow(img_np)\n","            ax2.set_title(\"Predictions\")\n","\n","            # Draw prediction boxes\n","            pred_boxes = pred['boxes'].cpu().numpy()\n","            pred_scores = pred['scores'].cpu().numpy()\n","            pred_labels = pred['labels'].cpu().numpy()\n","\n","            # Filter by confidence threshold\n","            keep = pred_scores >= confidence_threshold\n","            pred_boxes = pred_boxes[keep]\n","            pred_scores = pred_scores[keep]\n","            pred_labels = pred_labels[keep]\n","\n","            for box, score, label in zip(pred_boxes, pred_scores, pred_labels):\n","                x1, y1, x2, y2 = box\n","                width = x2 - x1\n","                height = y2 - y1\n","\n","                # Get color for this class\n","                color = colors[label % len(colors)]\n","                color_rgb = [c/255 for c in color]  # Convert to RGB [0,1]\n","\n","                # Create rectangle\n","                rect = patches.Rectangle((x1, y1), width, height, linewidth=2, edgecolor=color_rgb, facecolor='none')\n","                ax2.add_patch(rect)\n","\n","                # Add label\n","                class_name = CLASS_NAMES[label] if label < len(CLASS_NAMES) else f\"Class {label}\"\n","                text = f\"{class_name}: {score:.2f}\"\n","                ax2.text(x1, y1, text, backgroundcolor=color_rgb, color='white', fontsize=8)\n","\n","            # Remove axes ticks\n","            ax1.set_xticks([])\n","            ax1.set_yticks([])\n","            ax2.set_xticks([])\n","            ax2.set_yticks([])\n","\n","            # Set super title\n","            fig.suptitle(f\"Sample {count+1}: {len(gt_boxes)} ground truth, {len(pred_boxes)} predictions\")\n","            plt.tight_layout()\n","\n","            # Save or show\n","            if output_dir:\n","                plt.savefig(os.path.join(output_dir, f\"comparison_{count+1}.png\"))\n","                plt.close()\n","            else:\n","                plt.show()\n","\n","            count += 1\n","\n","            # Break if we've visualized enough samples\n","            if count >= num_samples:\n","                break\n","\n","        # Break if we've visualized enough samples\n","        if count >= num_samples:\n","            break\n","\n","def create_video_visualization(model, input_video_path, output_video_path, confidence_threshold=CONFIDENCE_THRESHOLD):\n","    # Set model to evaluation mode\n","    model.eval()\n","    device = next(model.parameters()).device\n","\n","    # Open video\n","    cap = cv2.VideoCapture(input_video_path)\n","\n","    # Check if video opened successfully\n","    if not cap.isOpened():\n","        print(f\"Error: Could not open video {input_video_path}\")\n","        return\n","\n","    # Get video properties\n","    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","    # Create video writer\n","    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n","\n","    # Transformation for preprocessing\n","    transform = transforms.Compose([\n","        transforms.ToPILImage(),\n","        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","\n","    # Colors for each class\n","    colors = [\n","        (255, 0, 0),    # Red\n","        (0, 255, 0),    # Green\n","        (0, 0, 255),    # Blue\n","        (255, 255, 0),  # Yellow\n","        (255, 0, 255),  # Magenta\n","    ]\n","\n","    # Process each frame\n","    frame_count = 0\n","    while cap.isOpened():\n","        # Read frame\n","        ret, frame = cap.read()\n","\n","        if not ret:\n","            break\n","\n","        # Preprocess frame\n","        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        input_tensor = transform(frame_rgb).unsqueeze(0).to(device)\n","\n","        # Get predictions\n","        with torch.no_grad():\n","            with autocast(device_type='cuda' if device.type == 'cuda' else 'cpu'):\n","                predictions = model(input_tensor)[0]\n","\n","        # Get boxes, scores, and labels\n","        boxes = predictions['boxes'].cpu().numpy()\n","        scores = predictions['scores'].cpu().numpy()\n","        labels = predictions['labels'].cpu().numpy()\n","\n","        # Filter by confidence threshold\n","        keep = scores >= confidence_threshold\n","        boxes = boxes[keep]\n","        scores = scores[keep]\n","        labels = labels[keep]\n","\n","        # Scale boxes to original frame size\n","        scale_x = frame_width / IMAGE_SIZE\n","        scale_y = frame_height / IMAGE_SIZE\n","\n","        scaled_boxes = []\n","        for box in boxes:\n","            x1, y1, x2, y2 = box\n","            scaled_boxes.append([\n","                int(x1 * scale_x), int(y1 * scale_y),\n","                int(x2 * scale_x), int(y2 * scale_y)\n","            ])\n","\n","        boxes = np.array(scaled_boxes, dtype=np.int32)\n","\n","        # Draw boxes and labels on the frame\n","        for box, score, label in zip(boxes, scores, labels):\n","            x1, y1, x2, y2 = box\n","\n","            # Get color for this class\n","            color = colors[label % len(colors)]\n","\n","            # Draw box\n","            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n","\n","            # Draw label\n","            class_name = CLASS_NAMES[label] if label < len(CLASS_NAMES) else f\"Class {label}\"\n","            text = f\"{class_name}: {score:.2f}\"\n","\n","            # Get text size\n","            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n","            text_w, text_h = text_size\n","\n","            # Draw text background\n","            cv2.rectangle(frame, (x1, y1), (x1 + text_w, y1 - text_h - 5), color, -1)\n","\n","            # Draw text\n","            cv2.putText(frame, text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n","\n","        # Draw frame number\n","        cv2.putText(frame, f\"Frame: {frame_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","\n","        # Write frame\n","        out.write(frame)\n","\n","        # Increment frame counter\n","        frame_count += 1\n","\n","        # Print progress\n","        if frame_count % 100 == 0:\n","            print(f\"Processed {frame_count} frames\")\n","\n","    # Release resources\n","    cap.release()\n","    out.release()\n","\n","    print(f\"Video processing completed. Output saved to {output_video_path}\")\n","\n","if __name__ == \"__main__\":\n","    # Load model\n","    model = load_model()\n","\n","    if model is None:\n","        print(\"Failed to load model.\")\n","        exit(1)\n","\n","    # Create a dataset for visualization\n","    from data import get_data_transforms\n","    _, val_transform = get_data_transforms()\n","\n","    # Create a test dataset\n","    test_dataset = RiceLeafDataset(root=TEST_DIR, annFile=TEST_ANNO, transform=val_transform)\n","\n","    # Visualize dataset samples\n","    output_dir = os.path.join(OUTPUT_DIR, \"visualizations\", \"samples\")\n","    os.makedirs(output_dir, exist_ok=True)\n","    visualize_dataset_samples(test_dataset, num_samples=5, output_dir=output_dir)\n","\n","    # Get test dataloader for batch predictions\n","    from data import get_dataloaders\n","    _, _, test_loader = get_dataloaders()\n","\n","    # Visualize batch predictions\n","    output_dir = os.path.join(OUTPUT_DIR, \"visualizations\", \"predictions\")\n","    os.makedirs(output_dir, exist_ok=True)\n","    visualize_batch_predictions(model, test_loader, num_samples=5, output_dir=output_dir)"],"metadata":{"id":"3doEItKFNve9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile evaluate.py\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import json\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, precision_recall_curve, average_precision_score, f1_score\n","from torch.cuda.amp import autocast\n","from pycocotools.coco import COCO\n","from pycocotools.cocoeval import COCOeval\n","\n","from model import load_model\n","from data import get_dataloaders\n","from config import *\n","\n","def convert_to_coco_format(predictions, image_ids, output_file=None):\n","    coco_predictions = []\n","\n","    for pred, img_id in zip(predictions, image_ids):\n","        boxes = pred['boxes'].cpu().numpy()\n","        scores = pred['scores'].cpu().numpy()\n","        labels = pred['labels'].cpu().numpy()\n","\n","        for box, score, label in zip(boxes, scores, labels):\n","            # Skip low-confidence predictions\n","            if score < CONFIDENCE_THRESHOLD:\n","                continue\n","\n","            # Convert box from [x1, y1, x2, y2] to [x, y, width, height]\n","            x1, y1, x2, y2 = box\n","            x, y, w, h = x1, y1, x2 - x1, y2 - y1\n","\n","            # Create prediction entry\n","            pred_entry = {\n","                'image_id': int(img_id),\n","                'category_id': int(label),\n","                'bbox': [float(x), float(y), float(w), float(h)],\n","                'score': float(score)\n","            }\n","\n","            coco_predictions.append(pred_entry)\n","\n","    # Save to file if specified\n","    if output_file:\n","        with open(output_file, 'w') as f:\n","            json.dump(coco_predictions, f)\n","        print(f\"Saved COCO format predictions to {output_file}\")\n","\n","    return coco_predictions\n","\n","def evaluate_coco(model, dataloader, anno_file, output_dir=None):\n","    model.eval()\n","    device = next(model.parameters()).device\n","\n","    # Lists to store predictions\n","    all_predictions = []\n","    all_image_ids = []\n","\n","    print(\"Running inference on dataset...\")\n","\n","    with torch.no_grad():\n","        for i, (images, targets) in enumerate(dataloader):\n","            # Move images to device\n","            images = [img.to(device) for img in images]\n","\n","            # Get image IDs\n","            image_ids = [target['image_id'].item() for target in targets]\n","\n","            # Run inference with mixed precision\n","            with autocast(device_type='cuda' if device.type == 'cuda' else 'cpu'):\n","                outputs = model(images)\n","\n","            all_predictions.extend(outputs)\n","            all_image_ids.extend(image_ids)\n","\n","            # Print progress\n","            if (i + 1) % 10 == 0:\n","                print(f\"Processed {i+1}/{len(dataloader)} batches\", end='\\r')\n","\n","    print(f\"\\nProcessed {len(all_predictions)} images.\")\n","\n","    # Convert predictions to COCO format\n","    output_file = os.path.join(output_dir, \"coco_predictions.json\") if output_dir else None\n","    coco_predictions = convert_to_coco_format(all_predictions, all_image_ids, output_file)\n","\n","    # Load COCO API for ground truth\n","    coco_gt = COCO(anno_file)\n","\n","    # Create COCO API for predictions\n","    coco_dt = coco_gt.loadRes(coco_predictions)\n","\n","    # Run COCO evaluation\n","    print(\"Running COCO evaluation...\")\n","    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n","    coco_eval.evaluate()\n","    coco_eval.accumulate()\n","    coco_eval.summarize()\n","\n","    # Extract results\n","    results = {\n","        'AP': coco_eval.stats[0],\n","        'AP50': coco_eval.stats[1],\n","        'AP75': coco_eval.stats[2],\n","        'APs': coco_eval.stats[3],\n","        'APm': coco_eval.stats[4],\n","        'APl': coco_eval.stats[5],\n","        'ARmax1': coco_eval.stats[6],\n","        'ARmax10': coco_eval.stats[7],\n","        'ARmax100': coco_eval.stats[8],\n","        'ARs': coco_eval.stats[9],\n","        'ARm': coco_eval.stats[10],\n","        'ARl': coco_eval.stats[11]\n","    }\n","\n","    # Save results to file if specified\n","    if output_dir:\n","        results_file = os.path.join(output_dir, \"coco_results.json\")\n","        with open(results_file, 'w') as f:\n","            json.dump(results, f, indent=4)\n","        print(f\"Saved evaluation results to {results_file}\")\n","\n","    return results, coco_eval\n","\n","def compute_confusion_matrix(model, dataloader, num_classes=NUM_CLASSES):\n","    model.eval()\n","    device = next(model.parameters()).device\n","\n","    # Initialize lists to store true and predicted labels\n","    y_true = []\n","    y_pred = []\n","    y_scores = []\n","\n","    print(\"Computing confusion matrix...\")\n","\n","    with torch.no_grad():\n","        for images, targets in dataloader:\n","            # Move images to device\n","            images = [img.to(device) for img in images]\n","\n","            # Forward pass\n","            outputs = model(images)\n","\n","            # For each image in the batch\n","            for i, (output, target) in enumerate(zip(outputs, targets)):\n","                pred_boxes = output['boxes'].cpu().numpy()\n","                pred_labels = output['labels'].cpu().numpy()\n","                pred_scores = output['scores'].cpu().numpy()\n","\n","                gt_boxes = target['boxes'].cpu().numpy()\n","                gt_labels = target['labels'].cpu().numpy()\n","\n","                # Skip if no ground truth or predictions\n","                if len(gt_boxes) == 0 or len(pred_boxes) == 0:\n","                    continue\n","\n","                # Filter predictions by confidence\n","                conf_mask = pred_scores >= CONFIDENCE_THRESHOLD\n","                pred_boxes = pred_boxes[conf_mask]\n","                pred_labels = pred_labels[conf_mask]\n","                pred_scores = pred_scores[conf_mask]\n","\n","                # Skip if no predictions after filtering\n","                if len(pred_boxes) == 0:\n","                    continue\n","\n","                # Calculate IoU between each prediction and ground truth box\n","                ious = np.zeros((len(pred_boxes), len(gt_boxes)))\n","                for p_idx, pred_box in enumerate(pred_boxes):\n","                    for g_idx, gt_box in enumerate(gt_boxes):\n","                        # Calculate intersection coordinates\n","                        x1 = max(pred_box[0], gt_box[0])\n","                        y1 = max(pred_box[1], gt_box[1])\n","                        x2 = min(pred_box[2], gt_box[2])\n","                        y2 = min(pred_box[3], gt_box[3])\n","\n","                        # Calculate intersection area\n","                        w = max(0, x2 - x1)\n","                        h = max(0, y2 - y1)\n","                        intersection = w * h\n","\n","                        # Calculate union area\n","                        pred_area = (pred_box[2] - pred_box[0]) * (pred_box[3] - pred_box[1])\n","                        gt_area = (gt_box[2] - gt_box[0]) * (gt_box[3] - gt_box[1])\n","                        union = pred_area + gt_area - intersection\n","\n","                        # Calculate IoU\n","                        iou = intersection / union if union > 0 else 0\n","                        ious[p_idx, g_idx] = iou\n","\n","                # Match predictions to ground truth based on IoU\n","                matched_gt_indices = np.argmax(ious, axis=1)\n","\n","                # Only count matches with IoU above threshold\n","                valid_matches = np.max(ious, axis=1) >= IOU_THRESHOLD\n","\n","                for p_idx, (pred_label, gt_idx, valid) in enumerate(zip(pred_labels, matched_gt_indices, valid_matches)):\n","                    if valid:\n","                        y_true.append(gt_labels[gt_idx])\n","                        y_pred.append(pred_label)\n","                        y_scores.append(pred_scores[p_idx])\n","\n","    # Compute confusion matrix\n","    cm = confusion_matrix(y_true, y_pred, labels=range(1, num_classes))  # Skip background class (0)\n","\n","    return cm, y_true, y_pred, y_scores\n","\n","def plot_confusion_matrix(cm, class_names=None, output_file=None):\n","    if class_names is None:\n","        class_names = [CLASS_NAMES[i] for i in range(1, len(CLASS_NAMES))]  # Skip background class\n","\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","    plt.title('Confusion Matrix')\n","    plt.xlabel('Predicted Label')\n","    plt.ylabel('True Label')\n","\n","    if output_file:\n","        plt.savefig(output_file)\n","        print(f\"Saved confusion matrix to {output_file}\")\n","    else:\n","        plt.show()\n","\n","    plt.close()\n","\n","def plot_precision_recall_curve(y_true, y_pred, y_scores, num_classes=NUM_CLASSES, output_file=None):\n","    # Convert to numpy arrays\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","    y_scores = np.array(y_scores)\n","\n","    plt.figure(figsize=(10, 8))\n","\n","    # For each class (skip background)\n","    for cls in range(1, num_classes):\n","        # Prepare binary classification problem\n","        binary_true = (y_true == cls).astype(int)\n","\n","        # Get scores for this class\n","        cls_scores = np.zeros_like(y_scores)\n","        cls_scores[y_pred == cls] = y_scores[y_pred == cls]\n","\n","        # Calculate precision-recall curve\n","        precision, recall, _ = precision_recall_curve(binary_true, cls_scores)\n","\n","        # Calculate average precision\n","        ap = average_precision_score(binary_true, cls_scores, average='macro')\n","\n","        # Plot\n","        plt.plot(recall, precision, lw=2, label=f'{CLASS_NAMES[cls]} (AP={ap:.2f})')\n","\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.title('Precision-Recall Curve')\n","    plt.legend(loc='best')\n","    plt.grid(True)\n","\n","    if output_file:\n","        plt.savefig(output_file)\n","        print(f\"Saved precision-recall curve to {output_file}\")\n","    else:\n","        plt.show()\n","\n","    plt.close()\n","\n","def plot_f1_curve(y_true, y_pred, y_scores, num_classes=NUM_CLASSES, output_file=None):\n","    # Convert to numpy arrays\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","    y_scores = np.array(y_scores)\n","\n","    plt.figure(figsize=(10, 8))\n","\n","    # For each class (skip background)\n","    for cls in range(1, num_classes):\n","        # Prepare binary classification problem\n","        binary_true = (y_true == cls).astype(int)\n","\n","        # Get scores for this class\n","        cls_scores = np.zeros_like(y_scores)\n","        cls_scores[y_pred == cls] = y_scores[y_pred == cls]\n","\n","        # Calculate precision-recall curve\n","        precision, recall, thresholds = precision_recall_curve(binary_true, cls_scores)\n","\n","        # Calculate F1 scores at each threshold\n","        f1_scores = np.zeros_like(precision)\n","        for i in range(len(precision)):\n","            if precision[i] + recall[i] > 0:  # Avoid division by zero\n","                f1_scores[i] = 2 * precision[i] * recall[i] / (precision[i] + recall[i])\n","\n","        # Plot\n","        plt.plot(recall, f1_scores, lw=2, label=f'{CLASS_NAMES[cls]}')\n","\n","    plt.xlabel('Recall')\n","    plt.ylabel('F1 Score')\n","    plt.title('F1 Score vs Recall Curve')\n","    plt.legend(loc='best')\n","    plt.grid(True)\n","\n","    if output_file:\n","        plt.savefig(output_file)\n","        print(f\"Saved F1 curve to {output_file}\")\n","    else:\n","        plt.show()\n","\n","    plt.close()\n","\n","def calculate_metrics(y_true, y_pred, num_classes=NUM_CLASSES):\n","    metrics = {}\n","\n","    # Convert to numpy arrays\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","\n","    # Calculate overall metrics\n","    metrics['accuracy'] = np.mean(y_true == y_pred)\n","\n","    # Calculate per-class metrics\n","    for cls in range(1, num_classes):  # Skip background class\n","        # Binary classification problem\n","        binary_true = (y_true == cls).astype(int)\n","        binary_pred = (y_pred == cls).astype(int)\n","\n","        # True positives, false positives, false negatives\n","        tp = np.sum((binary_true == 1) & (binary_pred == 1))\n","        fp = np.sum((binary_true == 0) & (binary_pred == 1))\n","        fn = np.sum((binary_true == 1) & (binary_pred == 0))\n","\n","        # Precision, recall, F1\n","        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n","        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n","        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n","\n","        metrics[f'class_{cls}_precision'] = precision\n","        metrics[f'class_{cls}_recall'] = recall\n","        metrics[f'class_{cls}_f1'] = f1\n","\n","    return metrics\n","\n","def evaluate_model(model_path=None, output_dir=None):\n","    # Use default paths if not specified\n","    if model_path is None:\n","        model_path = MODEL_SAVE_PATH\n","\n","    if output_dir is None:\n","        output_dir = METRICS_SAVE_PATH\n","\n","    # Create output directory if it doesn't exist\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Load model\n","    model = load_model(model_path)\n","    if model is None:\n","        print(f\"Failed to load model from {model_path}\")\n","        return None\n","\n","    # Set model to evaluation mode\n","    model.eval()\n","\n","    # Get test dataloader\n","    _, _, test_loader = get_dataloaders()\n","\n","    # Run COCO evaluation\n","    print(\"\\nRunning COCO evaluation...\")\n","    coco_results, coco_eval = evaluate_coco(model, test_loader, TEST_ANNO, output_dir)\n","\n","    # Compute confusion matrix\n","    print(\"\\nComputing confusion matrix...\")\n","    cm, y_true, y_pred, y_scores = compute_confusion_matrix(model, test_loader)\n","\n","    # Plot confusion matrix\n","    if len(y_true) > 0:\n","        plot_confusion_matrix(cm, class_names=[CLASS_NAMES[i] for i in range(1, NUM_CLASSES)],\n","                            output_file=CONFUSION_MATRIX_PATH)\n","\n","        # Plot precision-recall curve\n","        plot_precision_recall_curve(y_true, y_pred, y_scores,\n","                                   output_file=PR_CURVE_PATH)\n","\n","        # Plot F1 curve\n","        plot_f1_curve(y_true, y_pred, y_scores,\n","                     output_file=F1_CURVE_PATH)\n","\n","        # Calculate additional metrics\n","        metrics = calculate_metrics(y_true, y_pred)\n","\n","        # Combine all results\n","        results = {\n","            'coco_metrics': coco_results,\n","            'confusion_matrix': cm.tolist(),\n","            'classification_metrics': metrics,\n","            'num_matched_predictions': len(y_true)\n","        }\n","\n","        # Save all results to file\n","        results_file = os.path.join(output_dir, \"evaluation_results.json\")\n","        with open(results_file, 'w') as f:\n","            json.dump(results, f, indent=4)\n","\n","        print(f\"\\nSaved complete evaluation results to {results_file}\")\n","\n","        # Print summary\n","        print(\"\\nEvaluation Summary:\")\n","        print(f\"- mAP (IoU=0.50:0.95): {coco_results['AP']:.4f}\")\n","        print(f\"- mAP (IoU=0.50): {coco_results['AP50']:.4f}\")\n","        print(f\"- mAP (IoU=0.75): {coco_results['AP75']:.4f}\")\n","        print(f\"- Overall accuracy: {metrics['accuracy']:.4f}\")\n","\n","        # Print per-class metrics\n","        print(\"\\nPer-class metrics:\")\n","        for cls in range(1, NUM_CLASSES):\n","            print(f\"- {CLASS_NAMES[cls]}:\")\n","            print(f\"  - Precision: {metrics[f'class_{cls}_precision']:.4f}\")\n","            print(f\"  - Recall: {metrics[f'class_{cls}_recall']:.4f}\")\n","            print(f\"  - F1 Score: {metrics[f'class_{cls}_f1']:.4f}\")\n","\n","        return results\n","    else:\n","        print(\"No matched predictions found. Cannot compute confusion matrix and metrics.\")\n","\n","        # Save just the COCO results\n","        results = {\n","            'coco_metrics': coco_results,\n","            'num_matched_predictions': 0\n","        }\n","\n","        results_file = os.path.join(output_dir, \"evaluation_results.json\")\n","        with open(results_file, 'w') as f:\n","            json.dump(results, f, indent=4)\n","\n","        print(f\"\\nSaved partial evaluation results to {results_file}\")\n","\n","        return results\n","\n","if __name__ == \"__main__\":\n","    # Evaluate the model\n","    evaluate_model()"],"metadata":{"id":"p9aACPHNPP6A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile main.py\n","import os\n","import time\n","import argparse\n","import torch\n","from config import *\n","\n","def print_header(text):\n","    \"\"\"Print a section header.\"\"\"\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"{text}\")\n","    print(\"=\"*50)\n","\n","def main():\n","    # Parse command-line arguments\n","    parser = argparse.ArgumentParser(description=\"Rice Leaf Disease Detection with SSD\")\n","    parser.add_argument(\"--skip-setup\", action=\"store_true\", help=\"Skip setup steps\")\n","    parser.add_argument(\"--skip-train\", action=\"store_true\", help=\"Skip training\")\n","    parser.add_argument(\"--skip-evaluate\", action=\"store_true\", help=\"Skip evaluation\")\n","    parser.add_argument(\"--skip-visualize\", action=\"store_true\", help=\"Skip visualization\")\n","    parser.add_argument(\"--resume\", action=\"store_true\", help=\"Resume training from checkpoint\")\n","    parser.add_argument(\"--model-path\", type=str, help=\"Path to model weights\")\n","    parser.add_argument(\"--test-image\", type=str, help=\"Path to single test image for visualization\")\n","    parser.add_argument(\"--test-video\", type=str, help=\"Path to test video for visualization\")\n","    args = parser.parse_args()\n","\n","    # Start timer\n","    start_time = time.time()\n","\n","    # Step 1: Setup\n","    if not args.skip_setup:\n","        print_header(\"SETUP\")\n","        from setup import setup_all\n","\n","        if not setup_all():\n","            print(\"Setup failed. Exiting.\")\n","            return\n","\n","    # Import config after setup\n","    print_config()\n","\n","    # Step 2: Training\n","    model = None\n","    if not args.skip_train:\n","        print_header(\"TRAINING\")\n","        from train import train_model\n","\n","        # Use specified model path or default\n","        model_path = args.model_path if args.resume and args.model_path else None\n","\n","        # Train the model\n","        model, loss_history = train_model(resume_from=model_path)\n","\n","    # Step 3: Evaluation\n","    if not args.skip_evaluate:\n","        print_header(\"EVALUATION\")\n","        from evaluate import evaluate_model\n","\n","        # Use specified model path or trained model\n","        model_path = args.model_path if args.model_path else MODEL_SAVE_PATH\n","\n","        # Evaluate the model\n","        evaluation_results = evaluate_model(model_path=model_path)\n","\n","        if evaluation_results:\n","            print(\"Evaluation complete.\")\n","        else:\n","            print(\"Evaluation failed.\")\n","\n","    # Step 4: Visualization\n","    if not args.skip_visualize:\n","        print_header(\"VISUALIZATION\")\n","        from visualize import visualize_dataset_samples, visualize_prediction, visualize_batch_predictions\n","        from visualize import create_video_visualization\n","        from data import RiceLeafDataset, get_dataloaders, get_data_transforms\n","\n","        # Load model if not already loaded\n","        if model is None:\n","            from model import load_model\n","            model_path = args.model_path if args.model_path else MODEL_SAVE_PATH\n","            model = load_model(model_path)\n","\n","            if model is None:\n","                print(\"Failed to load model for visualization. Skipping.\")\n","                return\n","\n","        # Create visualization directory\n","        vis_dir = os.path.join(OUTPUT_DIR, \"visualizations\")\n","        os.makedirs(vis_dir, exist_ok=True)\n","\n","        # Visualize dataset samples\n","        print(\"Visualizing dataset samples...\")\n","        _, val_transform = get_data_transforms()\n","        test_dataset = RiceLeafDataset(root=TEST_DIR, annFile=TEST_ANNO, transform=val_transform)\n","\n","        sample_dir = os.path.join(vis_dir, \"samples\")\n","        os.makedirs(sample_dir, exist_ok=True)\n","        visualize_dataset_samples(test_dataset, num_samples=5, output_dir=sample_dir)\n","\n","        # Visualize model predictions\n","        print(\"Visualizing model predictions...\")\n","        _, _, test_loader = get_dataloaders()\n","\n","        pred_dir = os.path.join(vis_dir, \"predictions\")\n","        os.makedirs(pred_dir, exist_ok=True)\n","        visualize_batch_predictions(model, test_loader, num_samples=5, output_dir=pred_dir)\n","\n","        # Visualize single test image if specified\n","        if args.test_image and os.path.exists(args.test_image):\n","            print(f\"Visualizing predictions on {args.test_image}...\")\n","            output_path = os.path.join(vis_dir, \"test_image_prediction.jpg\")\n","            visualize_prediction(model, args.test_image, output_path=output_path)\n","\n","        # Process test video if specified\n","        if args.test_video and os.path.exists(args.test_video):\n","            print(f\"Processing video {args.test_video}...\")\n","            output_path = os.path.join(vis_dir, \"test_video_prediction.mp4\")\n","            create_video_visualization(model, args.test_video, output_path)\n","\n","    # Print total execution time\n","    total_time = time.time() - start_time\n","    print_header(\"COMPLETED\")\n","\n","    hours, remainder = divmod(total_time, 3600)\n","    minutes, seconds = divmod(remainder, 60)\n","    print(f\"Total execution time: {int(hours)}h {int(minutes)}m {int(seconds)}s\")\n","    print(\"Rice Leaf Disease Detection with SSD completed successfully!\")\n","\n","if __name__ == \"__main__\":\n","    # Print welcome message\n","    print(\"Rice Leaf Disease Detection with SSD\")\n","    print(\"A PyTorch implementation for detecting rice leaf diseases using SSD\")\n","\n","    # Check CUDA availability\n","    print(f\"CUDA available: {torch.cuda.is_available()}\")\n","    if torch.cuda.is_available():\n","        print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n","\n","    # Run the main function\n","    main()\n","\n","\n","import os\n","import json\n","\n","# Đường dẫn thư mục dữ liệu\n","data_root = \"/content/drive/MyDrive/Coco_Dataset\"\n","\n","# Kiểm tra thư mục chính\n","if os.path.exists(data_root):\n","    print(f\"✅ Thư mục chính tồn tại: {data_root}\")\n","\n","    # Kiểm tra các thư mục con\n","    for folder in [\"train\", \"valid\", \"test\"]:\n","        folder_path = os.path.join(data_root, folder)\n","        if os.path.exists(folder_path):\n","            print(f\"✅ Thư mục {folder} tồn tại\")\n","\n","            # Kiểm tra file annotations\n","            anno_file = os.path.join(folder_path, \"_annotations.coco.json\")\n","            if os.path.exists(anno_file):\n","                # Đọc số lượng ảnh và annotations\n","                with open(anno_file, 'r') as f:\n","                    data = json.load(f)\n","                print(f\"   - Số lượng ảnh: {len(data.get('images', []))}\")\n","                print(f\"   - Số lượng annotations: {len(data.get('annotations', []))}\")\n","                print(f\"   - Số lượng categories: {len(data.get('categories', []))}\")\n","\n","                # Hiển thị thông tin về categories\n","                print(\"   - Danh sách categories:\")\n","                for cat in data.get('categories', []):\n","                    print(f\"      - ID: {cat['id']}, Name: {cat['name']}\")\n","            else:\n","                print(f\"❌ THIẾU file annotations: {anno_file}\")\n","\n","            # Kiểm tra số lượng ảnh\n","            img_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n","            print(f\"   - Số lượng file ảnh trong thư mục: {len(img_files)}\")\n","        else:\n","            print(f\"❌ THIẾU thư mục {folder}\")\n","else:\n","    print(f\"❌ THIẾU thư mục chính: {data_root}\")\n","    print(\"Vui lòng tạo thư mục Coco_Dataset trong Google Drive của bạn\")"],"metadata":{"id":"VR1J2SP8PQrf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from setup import setup_all\n","\n","print(\"==== THIẾT LẬP DỰ ÁN ====\")\n","setup_all()"],"metadata":{"id":"SQvZW_OJPVOC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from data import analyze_dataset, get_dataloaders, get_class_weights\n","\n","print(\"==== PHÂN TÍCH DỮ LIỆU ====\")\n","# Phân tích dữ liệu\n","analyze_dataset()\n","\n","# Tạo dataloaders và kiểm tra số lượng ảnh\n","print(\"\\nTạo dataloaders:\")\n","train_loader, val_loader, test_loader = get_dataloaders()\n","\n","# Tính toán trọng số lớp từ dữ liệu huấn luyện\n","print(\"\\nTính toán trọng số lớp:\")\n","class_weights = get_class_weights(train_loader)\n"],"metadata":{"id":"qtfTb3cxPjni"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from model import test_model, get_model_summary\n","\n","print(\"==== KIỂM TRA MÔ HÌNH ====\")\n","model = test_model()\n","\n","# Hiển thị tóm tắt về mô hình\n","print(\"\\nCấu trúc mô hình:\")\n","model_summary = get_model_summary(model)\n","print(model_summary)"],"metadata":{"id":"mKpsCE7bPmO0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from train import train_model\n","\n","print(\"==== BẮT ĐẦU HUẤN LUYỆN ====\")\n","# Huấn luyện mô hình từ đầu\n","# model, losses = train_model()\n","\n","model, losses = train_model(resume_from=\"/content/drive/MyDrive/Coco_Dataset/checkpoint.pth\")"],"metadata":{"id":"-6zyxUHWPpRV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from evaluate import evaluate_model\n","\n","print(\"==== ĐÁNH GIÁ MÔ HÌNH ====\")\n","evaluation_results = evaluate_model()"],"metadata":{"id":"MrSNwy2RP4Wl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from visualize import visualize_dataset_samples, visualize_batch_predictions, visualize_prediction\n","from data import RiceLeafDataset, get_data_transforms, get_dataloaders\n","from model import load_model\n","import os\n","\n","print(\"==== TRỰC QUAN HÓA KẾT QUẢ ====\")\n","\n","# Tạo thư mục visualizations\n","vis_dir = os.path.join(OUTPUT_DIR, \"visualizations\")\n","os.makedirs(vis_dir, exist_ok=True)\n","\n","# Hiển thị một số mẫu từ tập dữ liệu\n","print(\"Hiển thị mẫu dữ liệu:\")\n","_, val_transform = get_data_transforms()\n","test_dataset = RiceLeafDataset(root=TEST_DIR, annFile=TEST_ANNO, transform=val_transform)\n","\n","sample_dir = os.path.join(vis_dir, \"samples\")\n","os.makedirs(sample_dir, exist_ok=True)\n","visualize_dataset_samples(test_dataset, num_samples=3)\n","\n","# Hiển thị kết quả dự đoán\n","print(\"\\nHiển thị kết quả dự đoán:\")\n","# Tải mô hình đã huấn luyện\n","model = load_model()\n","if model is not None:\n","    # Tạo dataloader để thực hiện dự đoán\n","    _, _, test_loader = get_dataloaders()\n","\n","    # Hiển thị kết quả dự đoán\n","    pred_dir = os.path.join(vis_dir, \"predictions\")\n","    os.makedirs(pred_dir, exist_ok=True)\n","    visualize_batch_predictions(model, test_loader, num_samples=3)\n","else:\n","    print(\"Không thể tải mô hình. Vui lòng huấn luyện mô hình trước.\")"],"metadata":{"id":"PVslvlaeP79V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from visualize import visualize_prediction\n","from model import load_model\n","import os\n","from google.colab import files\n","\n","print(\"==== DỰ ĐOÁN TRÊN ẢNH TÙY CHỈNH ====\")\n","\n","# Tải lên ảnh\n","print(\"Tải lên ảnh lá lúa để dự đoán:\")\n","try:\n","    uploaded = files.upload()\n","except:\n","    # Sử dụng ảnh mẫu nếu không thể tải lên\n","    uploaded = {'sample.jpg': 'Sử dụng ảnh mẫu'}\n","    print(\"Không thể tải ảnh lên. Sử dụng ảnh mẫu từ tập test.\")\n","\n","if len(uploaded) > 0:\n","    # Tải mô hình\n","    model = load_model()\n","    if model is not None:\n","        # Thực hiện dự đoán trên từng ảnh tải lên\n","        for filename in uploaded.keys():\n","            print(f\"\\nDự đoán trên ảnh: {filename}\")\n","\n","            # Nếu đang sử dụng ảnh mẫu từ tập test\n","            if filename == 'sample.jpg' and 'Sử dụng ảnh mẫu' in uploaded[filename]:\n","                # Lấy ảnh mẫu từ tập test\n","                import glob\n","                test_images = glob.glob(os.path.join(TEST_DIR, \"*.jpg\"))\n","                if test_images:\n","                    img_path = test_images[0]\n","                else:\n","                    print(\"Không tìm thấy ảnh mẫu trong tập test.\")\n","                    continue\n","            else:\n","                img_path = filename\n","\n","            # Tạo thư mục output nếu chưa tồn tại\n","            output_dir = os.path.join(OUTPUT_DIR, \"custom_predictions\")\n","            os.makedirs(output_dir, exist_ok=True)\n","\n","            # Đường dẫn lưu kết quả\n","            output_path = os.path.join(output_dir, f\"pred_{filename}\")\n","\n","            # Thực hiện dự đoán và hiển thị kết quả\n","            visualize_prediction(model, img_path, output_path=output_path)\n","\n","            # Hiển thị ảnh kết quả\n","            from IPython.display import Image, display\n","            print(f\"Kết quả dự đoán được lưu tại: {output_path}\")\n","            display(Image(output_path))\n","    else:\n","        print(\"Không thể tải mô hình. Vui lòng huấn luyện mô hình trước.\")\n","else:\n","    print(\"Không có ảnh nào được tải lên.\")"],"metadata":{"id":"-Zjo3iVdT_Mt"},"execution_count":null,"outputs":[]}]}