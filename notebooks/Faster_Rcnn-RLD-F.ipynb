{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPPqRn1tsaLcS8Frg2+H4WP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Hệ thống phát hiện bệnh trên lá lúa sử dụng mô hình Faster R-CNN với backbone ResNet-50 FPN\n","từ thư viện Detectron2 của Facebook Research.\n","\n","Phát hiện 4 loại bệnh:\n","- Bacterial Blight (Bạc lá)\n","- Blast (Đạo ôn)\n","- Brown Spot (Đốm nâu)\n","- Tungro (Vàng lùn)\n","\n","Dữ liệu sử dụng định dạng COCO."],"metadata":{"id":"LAM_Z028WmiZ"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"4sOJAuTxWnt_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install torch torchvision torchaudio --upgrade\n","!pip install 'git+https://github.com/facebookresearch/detectron2.git' --user\n","!pip install tabulate matplotlib opencv-python"],"metadata":{"id":"tyI6xkDgW6am"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile config.py\n","import os\n","from detectron2.config import get_cfg\n","from detectron2 import model_zoo\n","\n","# Path settings\n","DATA_ROOT = \"/content/drive/MyDrive/Coco_Dataset\"\n","TRAIN_JSON = f\"{DATA_ROOT}/train/_annotations.coco.json\"\n","TRAIN_IMG = f\"{DATA_ROOT}/train\"\n","VAL_JSON = f\"{DATA_ROOT}/valid/_annotations.coco.json\"\n","VAL_IMG = f\"{DATA_ROOT}/valid\"\n","TEST_JSON = f\"{DATA_ROOT}/test/_annotations.coco.json\"\n","TEST_IMG = f\"{DATA_ROOT}/test\"\n","\n","# Remapped JSON paths\n","TRAIN_REMAP_JSON = f\"{DATA_ROOT}/train/_annotations_remap.coco.json\"\n","VAL_REMAP_JSON = f\"{DATA_ROOT}/valid/_annotations_remap.coco.json\"\n","TEST_REMAP_JSON = f\"{DATA_ROOT}/test/_annotations_remap.coco.json\"\n","\n","# Dataset names\n","TRAIN_DATASET = \"my_train\"\n","VAL_DATASET = \"my_val\"\n","TEST_DATASET = \"my_test\"\n","TRAIN_REMAP_DATASET = \"my_train_remap\"\n","VAL_REMAP_DATASET = \"my_val_remap\"\n","TEST_REMAP_DATASET = \"my_test_remap\"\n","\n","# Output directory for trained model\n","OUTPUT_DIR = \"/content/drive/MyDrive/Output_FasterRCNN\"\n","NUM_CLASSES = 4\n","\n","def get_default_config():\n","    \"\"\"\n","    Returns the default configuration for Faster RCNN model.\n","    \"\"\"\n","    cfg = get_cfg()\n","    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n","    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n","    cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n","    cfg.DATASETS.TRAIN = (TRAIN_REMAP_DATASET,)\n","    cfg.DATASETS.TEST = (VAL_REMAP_DATASET,)\n","\n","    # dataloader and GPU settings\n","    cfg.DATALOADER.NUM_WORKERS = 4\n","    cfg.SOLVER.IMS_PER_BATCH = 4\n","    cfg.SOLVER.BASE_LR = 0.00025\n","    cfg.SOLVER.MAX_ITER = 3000\n","    cfg.SOLVER.STEPS = []\n","    cfg.SOLVER.WARMUP_ITERS = 1000\n","    cfg.SOLVER.AMP.ENABLED = True\n","\n","    # ROI head settings\n","    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  # ROIs per image to train\n","    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5      # threshold for keeping detections\n","\n","    # output directory for trained model and results\n","    cfg.OUTPUT_DIR = OUTPUT_DIR\n","    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","\n","    return cfg"],"metadata":{"id":"YKzu-cPqXGKS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile setup.py\n","import os\n","import subprocess\n","import sys\n","from google.colab import drive\n","\n","def mount_drive():\n","    # gotta have that sweet data\n","    drive.mount('/content/drive')\n","    print(\"Drive mounted successfully!\")\n","\n","def check_gpu():\n","    try:\n","        gpu_info = subprocess.check_output('nvidia-smi', shell=True).decode('utf-8')\n","        print(\"GPU information:\")\n","        print(gpu_info)\n","        return True\n","    except:\n","        print(\"No GPU found or nvidia-smi command failed.\")\n","        return False\n","\n","def check_dataset():\n","    data_dir = \"/content/drive/MyDrive/Coco_Dataset\"\n","    try:\n","        train_dir = os.path.join(data_dir, \"train\")\n","        val_dir = os.path.join(data_dir, \"valid\")\n","        test_dir = os.path.join(data_dir, \"test\")\n","\n","        train_files = os.listdir(train_dir) if os.path.exists(train_dir) else []\n","        val_files = os.listdir(val_dir) if os.path.exists(val_dir) else []\n","        test_files = os.listdir(test_dir) if os.path.exists(test_dir) else []\n","\n","        print(f\"Found {len(train_files)} files in train folder\")\n","        print(f\"Found {len(val_files)} files in validation folder\")\n","        print(f\"Found {len(test_files)} files in test folder\")\n","\n","        # check for annotations\n","        train_json = os.path.join(train_dir, \"_annotations.coco.json\")\n","        val_json = os.path.join(val_dir, \"_annotations.coco.json\")\n","        test_json = os.path.join(test_dir, \"_annotations.coco.json\")\n","\n","        missing_files = []\n","        if not os.path.exists(train_json):\n","            missing_files.append(train_json)\n","        if not os.path.exists(val_json):\n","            missing_files.append(val_json)\n","        if not os.path.exists(test_json):\n","            missing_files.append(test_json)\n","\n","        if missing_files:\n","            print(\"Warning! Missing annotation files:\")\n","            for file in missing_files:\n","                print(f\"  - {file}\")\n","            return False\n","\n","        return True\n","    except Exception as e:\n","        print(f\"Error checking dataset: {e}\")\n","        return False\n","\n","def install_dependencies():\n","    packages = [\n","        \"pip install torch torchvision torchaudio --upgrade\",\n","        \"pip install 'git+https://github.com/facebookresearch/detectron2.git' --user\"\n","    ]\n","\n","    for pkg in packages:\n","        try:\n","            print(f\"Running: {pkg}\")\n","            subprocess.run(pkg, shell=True, check=True)\n","            print(\"Installation successful\")\n","        except subprocess.CalledProcessError as e:\n","            print(f\"Failed to run: {pkg}\")\n","            print(f\"Error: {e}\")\n","\n","    print(\"Checking installations...\")\n","    try:\n","        import torch\n","        import detectron2\n","        print(\"Torch version:\", torch.__version__)\n","        print(\"CUDA available:\", torch.cuda.is_available())\n","        print(\"Detectron2 version:\", detectron2.__version__)\n","        return True\n","    except ImportError as e:\n","        print(f\"Import error: {e}\")\n","        return False\n","\n","if __name__ == \"__main__\":\n","    print(\"Setting up Rice Leaf Disease Detection with Faster RCNN...\")\n","    mount_drive()\n","    gpu_available = check_gpu()\n","    if not gpu_available:\n","        print(\"Warning: No GPU detected. Training will be extremely slow.\")\n","        response = input(\"Continue anyway? (y/n): \")\n","        if response.lower() != 'y':\n","            sys.exit(0)\n","\n","    dataset_ok = check_dataset()\n","    if not dataset_ok:\n","        print(\"Warning: Dataset issues detected.\")\n","        response = input(\"Continue anyway? (y/n): \")\n","        if response.lower() != 'y':\n","            sys.exit(0)\n","\n","    deps_ok = install_dependencies()\n","    if not deps_ok:\n","        print(\"Error installing dependencies. Please check the logs.\")\n","        sys.exit(1)\n","\n","    print(\"Setup complete! Ready to rock and roll.\")"],"metadata":{"id":"Ucm6tJSPXQK7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile data.py\n","import json\n","import os\n","from detectron2.data.datasets import register_coco_instances\n","from detectron2.data import MetadataCatalog, DatasetCatalog\n","from config import *\n","\n","def register_datasets():\n","    # registering both original and remapped datasets\n","    # original datasets (1-indexed categories)\n","    register_coco_instances(TRAIN_DATASET, {}, TRAIN_JSON, TRAIN_IMG)\n","    register_coco_instances(VAL_DATASET, {}, VAL_JSON, VAL_IMG)\n","    register_coco_instances(TEST_DATASET, {}, TEST_JSON, TEST_IMG)\n","\n","    # create remapped jsons if they don't exist\n","    if not os.path.exists(TRAIN_REMAP_JSON):\n","        remap_categories(TRAIN_JSON, TRAIN_REMAP_JSON)\n","    if not os.path.exists(VAL_REMAP_JSON):\n","        remap_categories(VAL_JSON, VAL_REMAP_JSON)\n","    if not os.path.exists(TEST_REMAP_JSON):\n","        remap_categories(TEST_JSON, TEST_REMAP_JSON)\n","\n","    # remapped datasets (0-indexed categories for Detectron2)\n","    register_coco_instances(TRAIN_REMAP_DATASET, {}, TRAIN_REMAP_JSON, TRAIN_IMG)\n","    register_coco_instances(VAL_REMAP_DATASET, {}, VAL_REMAP_JSON, VAL_IMG)\n","    register_coco_instances(TEST_REMAP_DATASET, {}, TEST_REMAP_JSON, TEST_IMG)\n","\n","    # print metadata for verification\n","    metadata_train = MetadataCatalog.get(TRAIN_REMAP_DATASET)\n","    metadata_val = MetadataCatalog.get(VAL_REMAP_DATASET)\n","    metadata_test = MetadataCatalog.get(TEST_REMAP_DATASET)\n","\n","    print(\"Registered datasets:\")\n","    print(f\"  Train: {TRAIN_REMAP_DATASET}\")\n","    print(f\"  Val: {VAL_REMAP_DATASET}\")\n","    print(f\"  Test: {TEST_REMAP_DATASET}\")\n","\n","    return {\n","        \"train\": metadata_train,\n","        \"val\": metadata_val,\n","        \"test\": metadata_test\n","    }\n","\n","def remap_categories(in_json_path, out_json_path):\n","    \"\"\"\n","    Remap category IDs in COCO annotations from 1-indexed to 0-indexed.\n","\n","    Args:\n","        in_json_path: Path to the input JSON file with 1-indexed categories\n","        out_json_path: Path to save the remapped JSON file with 0-indexed categories\n","    \"\"\"\n","    print(f\"Remapping categories in {in_json_path}...\")\n","\n","    # read that original JSON\n","    with open(in_json_path, 'r') as f:\n","        data = json.load(f)\n","\n","    # map the ids: old_id -> new_id = old_id - 1\n","    mapping = {}\n","    new_categories = []\n","    for cat in data[\"categories\"]:\n","        old_id = cat[\"id\"]\n","        new_id = old_id - 1  # subtract 1 to make it 0-indexed\n","        mapping[old_id] = new_id\n","\n","        # update the category object\n","        new_cat = cat.copy()\n","        new_cat[\"id\"] = new_id\n","        new_categories.append(new_cat)\n","\n","    # replace the categories list\n","    data[\"categories\"] = new_categories\n","\n","    # now gotta update all the annotations to use the new category ids\n","    new_annotations = []\n","    for ann in data[\"annotations\"]:\n","        old_cat_id = ann[\"category_id\"]\n","        # if this category isn't in our mapping (shouldn't happen), skip it\n","        if old_cat_id not in mapping:\n","            print(f\"Warning: category_id {old_cat_id} not found in mapping\")\n","            continue\n","\n","        ann_copy = ann.copy()\n","        ann_copy[\"category_id\"] = mapping[old_cat_id]\n","        new_annotations.append(ann_copy)\n","\n","    # replace the annotations list\n","    data[\"annotations\"] = new_annotations\n","\n","    # write that bad boy out\n","    with open(out_json_path, 'w') as f:\n","        json.dump(data, f)\n","\n","    print(f\"Created remapped file: {out_json_path}\")\n","    print(f\"  Remapped {len(new_categories)} categories\")\n","    print(f\"  Updated {len(new_annotations)} annotations\")\n","\n","    return out_json_path\n","\n","def print_dataset_stats():\n","    \"\"\"\n","    Print statistics about the registered datasets.\n","    \"\"\"\n","    for name in [TRAIN_REMAP_DATASET, VAL_REMAP_DATASET, TEST_REMAP_DATASET]:\n","        try:\n","            # grab the dataset dicts\n","            dataset_dicts = DatasetCatalog.get(name)\n","\n","            # count images, annotations, and annotations per category\n","            num_images = len(dataset_dicts)\n","            num_annotations = sum(len(img_dict.get(\"annotations\", [])) for img_dict in dataset_dicts)\n","\n","            # count by category\n","            cats_count = {}\n","            for img_dict in dataset_dicts:\n","                for ann in img_dict.get(\"annotations\", []):\n","                    cat_id = ann.get(\"category_id\", -1)\n","                    cats_count[cat_id] = cats_count.get(cat_id, 0) + 1\n","\n","            # get category names\n","            metadata = MetadataCatalog.get(name)\n","            if hasattr(metadata, \"thing_classes\"):\n","                class_names = metadata.thing_classes\n","            else:\n","                class_names = [f\"Class {i}\" for i in range(NUM_CLASSES)]\n","\n","            # print the stats\n","            print(f\"\\nDataset: {name}\")\n","            print(f\"  Images: {num_images}\")\n","            print(f\"  Annotations: {num_annotations}\")\n","            print(f\"  Annotations per image: {num_annotations/num_images:.2f}\")\n","            print(\"  Annotations per category:\")\n","            for cat_id, count in sorted(cats_count.items()):\n","                if 0 <= cat_id < len(class_names):\n","                    class_name = class_names[cat_id]\n","                else:\n","                    class_name = f\"Unknown({cat_id})\"\n","                print(f\"    {class_name}: {count}\")\n","\n","        except Exception as e:\n","            print(f\"Error getting stats for {name}: {e}\")\n","\n","if __name__ == \"__main__\":\n","    # if run directly, register datasets and print stats\n","    register_datasets()\n","    print_dataset_stats()"],"metadata":{"id":"4OOqmIWLXdci"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile train.py\n","import os\n","import time\n","import torch\n","from detectron2.engine import DefaultTrainer\n","from detectron2.utils.logger import setup_logger\n","from detectron2.engine import hooks\n","from detectron2.evaluation import COCOEvaluator\n","\n","from config import get_default_config\n","from data import register_datasets\n","\n","class RiceTrainer(DefaultTrainer):\n","    \"\"\"\n","    Custom trainer that adds periodic validation during training.\n","    \"\"\"\n","    @classmethod\n","    def build_evaluator(cls, cfg, dataset_name):\n","        \"\"\"\n","        Build evaluator for the given dataset.\n","        \"\"\"\n","        return COCOEvaluator(dataset_name, cfg, False, output_dir=cfg.OUTPUT_DIR)\n","\n","    def build_hooks(self):\n","        \"\"\"\n","        Build a list of default hooks, including periodic validation.\n","        \"\"\"\n","        hooks_list = super().build_hooks()\n","\n","        # add validation hook that runs every validation_period iterations\n","        validation_period = 500  # validate every 500 iterations\n","        hooks_list.append(\n","            hooks.EvalHook(\n","                validation_period,\n","                lambda: self.test(self.cfg, self.model, [\"my_val_remap\"])\n","            )\n","        )\n","\n","        return hooks_list\n","\n","def train_model(cfg, resume=False):\n","    \"\"\"\n","    Train the Faster RCNN model with the given configuration.\n","\n","    Args:\n","        cfg: Detectron2 configuration object\n","        resume: Whether to resume from last checkpoint\n","    \"\"\"\n","    # set up logging\n","    setup_logger()\n","\n","    print(\"Starting training...\")\n","    print(f\"Training dataset: {cfg.DATASETS.TRAIN}\")\n","    print(f\"Validation dataset: {cfg.DATASETS.TEST}\")\n","    print(f\"Max iterations: {cfg.SOLVER.MAX_ITER}\")\n","    print(f\"Base learning rate: {cfg.SOLVER.BASE_LR}\")\n","    print(f\"Batch size: {cfg.SOLVER.IMS_PER_BATCH}\")\n","\n","    # check GPU\n","    if torch.cuda.is_available():\n","        num_gpus = torch.cuda.device_count()\n","        device_name = torch.cuda.get_device_name(0)\n","        print(f\"Using {num_gpus} GPU(s). Primary device: {device_name}\")\n","    else:\n","        print(\"Warning: No GPU detected. Training will be slow.\")\n","\n","    # time the training\n","    start_time = time.time()\n","\n","    try:\n","        # create trainer\n","        trainer = RiceTrainer(cfg)\n","        trainer.resume_or_load(resume=resume)\n","\n","        # train the model\n","        trainer.train()\n","\n","        # calculate training time\n","        train_time = (time.time() - start_time) / 60.0  # minutes\n","        print(f\"Training completed in {train_time:.2f} minutes\")\n","\n","        # get the path to the final model\n","        final_model_path = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","        print(f\"Final model saved to: {final_model_path}\")\n","\n","        return True, trainer\n","\n","    except Exception as e:\n","        print(f\"Training error: {e}\")\n","        train_time = (time.time() - start_time) / 60.0\n","        print(f\"Training failed after {train_time:.2f} minutes\")\n","        return False, None\n","\n","def save_model_config(cfg):\n","    \"\"\"\n","    Save the model configuration to a text file for reference.\n","    \"\"\"\n","    config_path = os.path.join(cfg.OUTPUT_DIR, \"model_config.txt\")\n","    with open(config_path, 'w') as f:\n","        # get all the important bits to save\n","        f.write(\"Rice Leaf Disease Detection - Faster RCNN Configuration\\n\")\n","        f.write(\"=\" * 60 + \"\\n\\n\")\n","\n","        f.write(f\"Model: Faster RCNN with ResNet-50 FPN backbone\\n\")\n","        f.write(f\"Number of classes: {cfg.MODEL.ROI_HEADS.NUM_CLASSES}\\n\")\n","        f.write(f\"Input resolution: {cfg.INPUT.MIN_SIZE_TRAIN}-{cfg.INPUT.MAX_SIZE_TRAIN}\\n\")\n","        f.write(f\"Batch size: {cfg.SOLVER.IMS_PER_BATCH}\\n\")\n","        f.write(f\"Base learning rate: {cfg.SOLVER.BASE_LR}\\n\")\n","        f.write(f\"Max iterations: {cfg.SOLVER.MAX_ITER}\\n\")\n","        f.write(f\"Warmup iterations: {cfg.SOLVER.WARMUP_ITERS}\\n\")\n","\n","        # other relevant params\n","        f.write(\"\\nDatasets:\\n\")\n","        f.write(f\"  Train: {cfg.DATASETS.TRAIN}\\n\")\n","        f.write(f\"  Test: {cfg.DATASETS.TEST}\\n\")\n","\n","        f.write(\"\\nROI Head settings:\\n\")\n","        f.write(f\"  ROIs per image: {cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE}\\n\")\n","        f.write(f\"  Score threshold: {cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST}\\n\")\n","\n","        f.write(\"\\nFull configuration (YAML format):\\n\")\n","        f.write(cfg.dump())\n","\n","    print(f\"Configuration saved to: {config_path}\")\n","\n","if __name__ == \"__main__\":\n","    # register the datasets\n","    register_datasets()\n","\n","    # get the default configuration\n","    cfg = get_default_config()\n","\n","    # save the config before training\n","    save_model_config(cfg)\n","\n","    # train the model\n","    success, trainer = train_model(cfg, resume=False)\n","\n","    if success:\n","        print(\"Training completed successfully! Model is ready for evaluation.\")\n","    else:\n","        print(\"Training failed. Check the log for errors.\")"],"metadata":{"id":"ybbnKPR6Xhvr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile evaluate.py\n","import os\n","import cv2\n","import torch\n","import numpy as np\n","from tabulate import tabulate\n","from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader, DatasetMapper\n","from detectron2.engine import DefaultPredictor\n","from detectron2.utils.logger import setup_logger\n","from detectron2.utils.visualizer import Visualizer, ColorMode\n","from detectron2.data import MetadataCatalog\n","\n","from config import get_default_config\n","from data import register_datasets\n","\n","def evaluate_model(cfg, dataset_name):\n","    \"\"\"\n","    Evaluate the trained model on the given dataset.\n","\n","    Args:\n","        cfg: Detectron2 configuration\n","        dataset_name: Name of the dataset to evaluate on\n","    \"\"\"\n","    # update config to use the final model\n","    model_path = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","    if not os.path.exists(model_path):\n","        print(f\"Error: Model file not found at {model_path}\")\n","        return None\n","\n","    cfg.MODEL.WEIGHTS = model_path\n","\n","    # set up evaluator for the dataset\n","    evaluator = COCOEvaluator(dataset_name, cfg, False, output_dir=cfg.OUTPUT_DIR)\n","\n","    # build data loader for the dataset\n","    test_loader = build_detection_test_loader(cfg, dataset_name)\n","\n","    # create predictor\n","    predictor = DefaultPredictor(cfg)\n","\n","    # run inference on the dataset\n","    print(f\"Evaluating model on {dataset_name}...\")\n","    results = inference_on_dataset(predictor.model, test_loader, evaluator)\n","\n","    # print the results in a nice format\n","    if \"segm\" in results:\n","        print(\"Segmentation results:\", results[\"segm\"])\n","\n","    if \"bbox\" in results:\n","        # grab the metrics we care about\n","        bbox_results = results[\"bbox\"]\n","        metrics = [\"AP\", \"AP50\", \"AP75\", \"APs\", \"APm\", \"APl\"]\n","\n","        # format as a table\n","        table_data = []\n","        for metric in metrics:\n","            if metric in bbox_results:\n","                table_data.append([metric, f\"{bbox_results[metric]:.4f}\"])\n","\n","        print(\"\\nDetection Results:\")\n","        print(tabulate(table_data, headers=[\"Metric\", \"Value\"], tablefmt=\"grid\"))\n","\n","    return results\n","\n","def compute_iou_matrix(boxes1, boxes2):\n","    \"\"\"\n","    Compute IoU matrix between two sets of bounding boxes.\n","\n","    Args:\n","        boxes1: np.array of shape (N,4) in [x1,y1,x2,y2] format\n","        boxes2: np.array of shape (M,4) in [x1,y1,x2,y2] format\n","\n","    Returns:\n","        iou_mat: np.array of shape (N,M) with IoU values\n","    \"\"\"\n","    # prepare that IoU matrix\n","    iou_mat = np.zeros((len(boxes1), len(boxes2)), dtype=np.float32)\n","\n","    # calculate IoU for each box pair\n","    for i, b1 in enumerate(boxes1):\n","        # area of first box\n","        area1 = (b1[2]-b1[0])*(b1[3]-b1[1])\n","\n","        for j, b2 in enumerate(boxes2):\n","            # area of second box\n","            area2 = (b2[2]-b2[0])*(b2[3]-b2[1])\n","\n","            # find intersection coords\n","            inter_x1 = max(b1[0], b2[0])\n","            inter_y1 = max(b1[1], b2[1])\n","            inter_x2 = min(b1[2], b2[2])\n","            inter_y2 = min(b1[3], b2[3])\n","\n","            # check if boxes overlap\n","            if inter_x2 < inter_x1 or inter_y2 < inter_y1:\n","                iou = 0.0\n","            else:\n","                # calculate areas\n","                inter_area = (inter_x2 - inter_x1)*(inter_y2 - inter_y1)\n","                union = area1 + area2 - inter_area\n","                iou = inter_area / union if union > 0 else 0.0\n","\n","            # store in the matrix\n","            iou_mat[i, j] = iou\n","\n","    return iou_mat\n","\n","def debug_validation_samples(cfg, dataset_name, max_images=3):\n","    model_path = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","    cfg.MODEL.WEIGHTS = model_path\n","\n","    # create a predictor and dataset loader\n","    mapper = DatasetMapper(cfg, is_train=True)\n","    val_loader = build_detection_test_loader(cfg, dataset_name, mapper=mapper)\n","    predictor = DefaultPredictor(cfg)\n","\n","    # get metadata for visualization\n","    metadata = MetadataCatalog.get(dataset_name)\n","\n","    # directory for saving debug visualizations\n","    debug_dir = os.path.join(cfg.OUTPUT_DIR, \"debug_visualizations\")\n","    os.makedirs(debug_dir, exist_ok=True)\n","\n","    count = 0\n","\n","    # process each image\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            inputs = batch[0]\n","            img_path = inputs[\"file_name\"]\n","            img = cv2.imread(img_path)\n","\n","            if img is None:\n","                print(f\"Error: Could not read image {img_path}\")\n","                continue\n","\n","            img_name = os.path.basename(img_path)\n","            print(f\"\\nDebug image {count+1}: {img_name}\")\n","\n","            # make predictions\n","            outputs = predictor(img)\n","            instances = outputs[\"instances\"].to(\"cpu\")\n","            pred_boxes = instances.pred_boxes.tensor.numpy()\n","            pred_classes = instances.pred_classes.numpy()\n","            pred_scores = instances.scores.numpy()\n","\n","            print(f\"Predictions: {len(pred_boxes)} boxes\")\n","\n","            # get ground truth\n","            gt_annotations = inputs.get(\"annotations\", [])\n","            gt_boxes = []\n","            gt_classes = []\n","\n","            for ann in gt_annotations:\n","                x, y, w, h = ann[\"bbox\"]\n","                x2, y2 = x + w, y + h\n","                gt_boxes.append([x, y, x2, y2])\n","                gt_classes.append(ann[\"category_id\"])\n","\n","            gt_boxes = np.array(gt_boxes)\n","            gt_classes = np.array(gt_classes)\n","\n","            print(f\"Ground truth: {len(gt_boxes)} boxes\")\n","\n","            # calculate IoU if both pred and GT exist\n","            if len(pred_boxes) > 0 and len(gt_boxes) > 0:\n","                iou_mat = compute_iou_matrix(pred_boxes, gt_boxes)\n","                max_ious = np.max(iou_mat, axis=1)\n","\n","                # calculate mIoU\n","                mean_iou = np.mean(max_ious)\n","                print(f\"Mean IoU: {mean_iou:.4f}\")\n","\n","                # print class-wise results\n","                if hasattr(metadata, \"thing_classes\"):\n","                    classes = metadata.thing_classes\n","\n","                    for cls_id in range(len(classes)):\n","                        # indices of predictions for this class\n","                        pred_idx = np.where(pred_classes == cls_id)[0]\n","                        gt_idx = np.where(gt_classes == cls_id)[0]\n","\n","                        # check if we have both pred and GT for this class\n","                        if len(pred_idx) > 0 and len(gt_idx) > 0:\n","                            # get IoUs only for this class\n","                            cls_ious = iou_mat[pred_idx][:, gt_idx]\n","                            if cls_ious.size > 0:\n","                                max_cls_iou = np.max(cls_ious, axis=1)\n","                                mean_cls_iou = np.mean(max_cls_iou)\n","                                print(f\"  Class '{classes[cls_id]}': {len(pred_idx)} pred, {len(gt_idx)} GT, mIoU: {mean_cls_iou:.4f}\")\n","\n","            # visualize predictions and ground truth\n","            vis_output = img.copy()\n","\n","            # visualize predictions\n","            v = Visualizer(\n","                img[:, :, ::-1],\n","                metadata=metadata,\n","                scale=1.0,\n","                instance_mode=ColorMode.IMAGE_BW\n","            )\n","            vis_pred = v.draw_instance_predictions(instances)\n","            vis_pred_img = vis_pred.get_image()[:, :, ::-1]\n","\n","            # save visualization\n","            output_path = os.path.join(debug_dir, f\"debug_{count}_{img_name}\")\n","            cv2.imwrite(output_path, vis_pred_img)\n","            print(f\"Debug visualization saved to: {output_path}\")\n","\n","            count += 1\n","            if count >= max_images:\n","                break\n","\n","def analyze_failure_cases(cfg, dataset_name, iou_threshold=0.5, max_images=10):\n","    # update to use the final model\n","    model_path = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","    cfg.MODEL.WEIGHTS = model_path\n","\n","    # create predictor\n","    predictor = DefaultPredictor(cfg)\n","\n","    # create data loader\n","    mapper = DatasetMapper(cfg, is_train=False)\n","    loader = build_detection_test_loader(cfg, dataset_name, mapper=mapper)\n","\n","    # get metadata\n","    metadata = MetadataCatalog.get(dataset_name)\n","    class_names = metadata.thing_classes if hasattr(metadata, \"thing_classes\") else [f\"Class {i}\" for i in range(cfg.MODEL.ROI_HEADS.NUM_CLASSES)]\n","\n","    # output dir for failure case visualizations\n","    output_dir = os.path.join(cfg.OUTPUT_DIR, \"failure_cases\")\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # counters for statistics\n","    total_tp = 0\n","    total_fp = 0\n","    total_fn = 0\n","    class_stats = {i: {\"tp\": 0, \"fp\": 0, \"fn\": 0} for i in range(len(class_names))}\n","\n","    count = 0\n","    with torch.no_grad():\n","        for batch in loader:\n","            inputs = batch[0]\n","            img_path = inputs[\"file_name\"]\n","            img = cv2.imread(img_path)\n","\n","            if img is None:\n","                print(f\"Error: Could not read image {img_path}\")\n","                continue\n","\n","            # get predictions\n","            outputs = predictor(img)\n","            instances = outputs[\"instances\"].to(\"cpu\")\n","            pred_boxes = instances.pred_boxes.tensor.numpy()\n","            pred_classes = instances.pred_classes.numpy()\n","            pred_scores = instances.scores.numpy()\n","\n","            # get ground truth\n","            gt_annotations = inputs.get(\"annotations\", [])\n","            gt_boxes = []\n","            gt_classes = []\n","\n","            for ann in gt_annotations:\n","                x, y, w, h = ann[\"bbox\"]\n","                x2, y2 = x + w, y + h\n","                gt_boxes.append([x, y, x2, y2])\n","                gt_classes.append(ann[\"category_id\"])\n","\n","            gt_boxes = np.array(gt_boxes) if gt_boxes else np.zeros((0, 4))\n","            gt_classes = np.array(gt_classes) if gt_classes else np.array([])\n","\n","            # compute IoU matrix\n","            if len(pred_boxes) > 0 and len(gt_boxes) > 0:\n","                iou_mat = compute_iou_matrix(pred_boxes, gt_boxes)\n","\n","                # for each prediction, find if it's TP or FP\n","                for i in range(len(pred_boxes)):\n","                    pred_class = pred_classes[i]\n","\n","                    # find GT boxes with same class\n","                    same_class_gt = np.where(gt_classes == pred_class)[0]\n","\n","                    if len(same_class_gt) > 0:\n","                        # get IoUs with same-class GT boxes\n","                        ious = iou_mat[i, same_class_gt]\n","                        max_iou_idx = np.argmax(ious)\n","                        max_iou = ious[max_iou_idx]\n","\n","                        if max_iou >= iou_threshold:\n","                            # true positive\n","                            total_tp += 1\n","                            class_stats[pred_class][\"tp\"] += 1\n","                        else:\n","                            # false positive (low IoU)\n","                            total_fp += 1\n","                            class_stats[pred_class][\"fp\"] += 1\n","                    else:\n","                        # false positive (no matching class)\n","                        total_fp += 1\n","                        class_stats[pred_class][\"fp\"] += 1\n","\n","                # find false negatives (GT boxes without matching predictions)\n","                for j in range(len(gt_boxes)):\n","                    gt_class = gt_classes[j]\n","\n","                    # find predictions with same class\n","                    same_class_pred = np.where(pred_classes == gt_class)[0]\n","\n","                    if len(same_class_pred) > 0:\n","                        # get IoUs with same-class predictions\n","                        ious = iou_mat[same_class_pred, j]\n","                        max_iou = np.max(ious)\n","\n","                        if max_iou < iou_threshold:\n","                            # false negative (low IoU)\n","                            total_fn += 1\n","                            class_stats[gt_class][\"fn\"] += 1\n","                    else:\n","                        # false negative (no matching prediction)\n","                        total_fn += 1\n","                        class_stats[gt_class][\"fn\"] += 1\n","            else:\n","                # if no predictions, all GT are false negatives\n","                for gt_class in gt_classes:\n","                    total_fn += 1\n","                    class_stats[gt_class][\"fn\"] += 1\n","\n","                # if no GT but have predictions, all predictions are false positives\n","                for pred_class in pred_classes:\n","                    total_fp += 1\n","                    class_stats[pred_class][\"fp\"] += 1\n","\n","            count += 1\n","            if count >= max_images:\n","                break\n","\n","    # print summary statistics\n","    print(\"\\nFailure Analysis Summary:\")\n","    print(f\"Total images analyzed: {count}\")\n","    print(f\"True Positives: {total_tp}\")\n","    print(f\"False Positives: {total_fp}\")\n","    print(f\"False Negatives: {total_fn}\")\n","\n","    # calculate precision and recall\n","    precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n","    recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n","    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"F1 Score: {f1:.4f}\")\n","\n","    # print class-wise statistics\n","    print(\"\\nClass-wise Statistics:\")\n","    headers = [\"Class\", \"TP\", \"FP\", \"FN\", \"Precision\", \"Recall\", \"F1\"]\n","    table_data = []\n","\n","    for cls_id, stats in class_stats.items():\n","        if cls_id >= len(class_names):\n","            continue\n","\n","        cls_tp = stats[\"tp\"]\n","        cls_fp = stats[\"fp\"]\n","        cls_fn = stats[\"fn\"]\n","\n","        # calculate metrics\n","        cls_precision = cls_tp / (cls_tp + cls_fp) if (cls_tp + cls_fp) > 0 else 0\n","        cls_recall = cls_tp / (cls_tp + cls_fn) if (cls_tp + cls_fn) > 0 else 0\n","        cls_f1 = 2 * (cls_precision * cls_recall) / (cls_precision + cls_recall) if (cls_precision + cls_recall) > 0 else 0\n","\n","        # add to table\n","        table_data.append([\n","            class_names[cls_id],\n","            cls_tp,\n","            cls_fp,\n","            cls_fn,\n","            f\"{cls_precision:.4f}\",\n","            f\"{cls_recall:.4f}\",\n","            f\"{cls_f1:.4f}\"\n","        ])\n","\n","    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n","\n","if __name__ == \"__main__\":\n","    # set up logger\n","    setup_logger()\n","\n","    # register datasets\n","    metadata_dict = register_datasets()\n","\n","    # get default config and update for evaluation\n","    cfg = get_default_config()\n","\n","    # make sure output dir exists\n","    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","\n","    # evaluate on validation set\n","    eval_results = evaluate_model(cfg, \"my_val_remap\")\n","\n","    # debug validation samples\n","    debug_validation_samples(cfg, \"my_val_remap\", max_images=3)\n","\n","    # analyze failure cases\n","    analyze_failure_cases(cfg, \"my_val_remap\", iou_threshold=0.5, max_images=10)"],"metadata":{"id":"AEgSW0dXXlRk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile predict.py\n","import os\n","import cv2\n","import numpy as np\n","import torch\n","import glob\n","from detectron2.engine import DefaultPredictor\n","from detectron2.utils.visualizer import Visualizer, ColorMode\n","from detectron2.data import MetadataCatalog\n","from detectron2.utils.logger import setup_logger\n","\n","from config import get_default_config\n","from data import register_datasets\n","\n","def load_model(cfg, weights_path=None):\n","    if weights_path is None:\n","        weights_path = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","\n","    if not os.path.exists(weights_path):\n","        print(f\"Error: Model weights not found at {weights_path}\")\n","        return None\n","\n","    # update config to use the specified weights\n","    cfg.MODEL.WEIGHTS = weights_path\n","\n","    # lower the confidence threshold for visualization\n","    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n","\n","    # create the predictor\n","    try:\n","        predictor = DefaultPredictor(cfg)\n","        print(f\"Model loaded from: {weights_path}\")\n","        return predictor\n","    except Exception as e:\n","        print(f\"Error loading model: {e}\")\n","        return None\n","\n","def predict_single_image(predictor, image_path, metadata, output_dir=None, show_image=False):\n","    # read the image\n","    img = cv2.imread(image_path)\n","\n","    if img is None:\n","        print(f\"Error: Could not read image {image_path}\")\n","        return None, None\n","\n","    # run prediction\n","    outputs = predictor(img)\n","\n","    # get the instances for visualization\n","    instances = outputs[\"instances\"].to(\"cpu\")\n","\n","    # print prediction summary\n","    num_instances = len(instances)\n","    print(f\"Found {num_instances} instances in {os.path.basename(image_path)}\")\n","\n","    if num_instances > 0:\n","        # get class names if available\n","        if hasattr(metadata, \"thing_classes\"):\n","            class_names = metadata.thing_classes\n","\n","            # count detections by class\n","            class_counts = {}\n","            for i in range(num_instances):\n","                class_id = instances.pred_classes[i].item()\n","                class_name = class_names[class_id] if class_id < len(class_names) else f\"Unknown({class_id})\"\n","                class_counts[class_name] = class_counts.get(class_name, 0) + 1\n","\n","            # print counts by class\n","            for class_name, count in class_counts.items():\n","                print(f\"  - {class_name}: {count}\")\n","\n","    # visualize the predictions\n","    visualizer = Visualizer(\n","        img[:, :, ::-1],  # BGR -> RGB\n","        metadata=metadata,\n","        scale=1.0,\n","        instance_mode=ColorMode.IMAGE_BW  # draw segmentations in their original colors\n","    )\n","    vis_output = visualizer.draw_instance_predictions(instances)\n","    vis_image = vis_output.get_image()[:, :, ::-1]  # RGB -> BGR\n","\n","    # save visualization if output directory is specified\n","    if output_dir is not None:\n","        os.makedirs(output_dir, exist_ok=True)\n","        output_path = os.path.join(output_dir, f\"pred_{os.path.basename(image_path)}\")\n","        cv2.imwrite(output_path, vis_image)\n","        print(f\"Visualization saved to: {output_path}\")\n","\n","    # show image if requested (useful in notebooks)\n","    if show_image:\n","        from google.colab.patches import cv2_imshow\n","        cv2_imshow(vis_image)\n","\n","    return outputs, vis_image\n","\n","def predict_batch(predictor, image_dir, metadata, output_dir=None, file_pattern=\"*.jpg\"):\n","    # find all matching image files\n","    image_paths = glob.glob(os.path.join(image_dir, file_pattern))\n","\n","    if not image_paths:\n","        print(f\"No images matching '{file_pattern}' found in {image_dir}\")\n","        return\n","\n","    print(f\"Found {len(image_paths)} images to process\")\n","\n","    # create output directory if specified\n","    if output_dir:\n","        os.makedirs(output_dir, exist_ok=True)\n","\n","    # process each image\n","    results = {}\n","    for i, image_path in enumerate(image_paths):\n","        print(f\"\\nProcessing image {i+1}/{len(image_paths)}: {os.path.basename(image_path)}\")\n","        outputs, _ = predict_single_image(predictor, image_path, metadata, output_dir)\n","\n","        if outputs is not None:\n","            results[image_path] = outputs\n","\n","    print(f\"\\nProcessed {len(results)} images successfully\")\n","    return results\n","\n","def analyze_predictions(results, metadata):\n","    if not results:\n","        print(\"No results to analyze\")\n","        return\n","\n","    # class names if available\n","    class_names = metadata.thing_classes if hasattr(metadata, \"thing_classes\") else []\n","\n","    # count total instances and instances by class\n","    total_instances = 0\n","    class_counts = {}\n","\n","    for image_path, outputs in results.items():\n","        instances = outputs[\"instances\"]\n","        num_instances = len(instances)\n","        total_instances += num_instances\n","\n","        # count by class\n","        if num_instances > 0 and len(class_names) > 0:\n","            for i in range(num_instances):\n","                class_id = instances.pred_classes[i].item()\n","                class_name = class_names[class_id] if class_id < len(class_names) else f\"Unknown({class_id})\"\n","                class_counts[class_name] = class_counts.get(class_name, 0) + 1\n","\n","    # print summary\n","    print(\"\\nPrediction Analysis:\")\n","    print(f\"Total images: {len(results)}\")\n","    print(f\"Total detected instances: {total_instances}\")\n","    print(f\"Average instances per image: {total_instances / len(results):.2f}\")\n","\n","    if class_counts:\n","        print(\"\\nDetections by class:\")\n","        for class_name, count in sorted(class_counts.items(), key=lambda x: x[1], reverse=True):\n","            print(f\"  - {class_name}: {count} ({count/total_instances*100:.1f}%)\")\n","\n","def create_video_predictions(predictor, video_path, metadata, output_path=None, fps=30):\n","    # open the video\n","    cap = cv2.VideoCapture(video_path)\n","\n","    if not cap.isOpened():\n","        print(f\"Error: Could not open video {video_path}\")\n","        return\n","\n","    # get video properties\n","    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","    # determine output path\n","    if output_path is None:\n","        base_name = os.path.splitext(os.path.basename(video_path))[0]\n","        output_path = os.path.join(os.path.dirname(video_path), f\"{base_name}_predictions.mp4\")\n","\n","    # create video writer\n","    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n","\n","    # process the video\n","    frame_count = 0\n","\n","    try:\n","        while cap.isOpened():\n","            ret, frame = cap.read()\n","\n","            if not ret:\n","                break\n","\n","            # run prediction on the frame\n","            outputs = predictor(frame)\n","            instances = outputs[\"instances\"].to(\"cpu\")\n","\n","            # visualize the predictions\n","            visualizer = Visualizer(\n","                frame[:, :, ::-1],  # BGR -> RGB\n","                metadata=metadata,\n","                scale=1.0,\n","                instance_mode=ColorMode.IMAGE_BW\n","            )\n","            vis_output = visualizer.draw_instance_predictions(instances)\n","            vis_frame = vis_output.get_image()[:, :, ::-1]  # RGB -> BGR\n","\n","            # write the frame to output video\n","            out.write(vis_frame)\n","\n","            # update progress\n","            frame_count += 1\n","            if frame_count % 10 == 0:\n","                print(f\"Processed {frame_count}/{num_frames} frames ({frame_count/num_frames*100:.1f}%)\", end=\"\\r\")\n","\n","    except Exception as e:\n","        print(f\"\\nError processing video: {e}\")\n","\n","    finally:\n","        # release resources\n","        cap.release()\n","        out.release()\n","        print(f\"\\nVideo processing complete. Output saved to: {output_path}\")\n","\n","if __name__ == \"__main__\":\n","    # set up logger\n","    setup_logger()\n","\n","    # register datasets\n","    metadata_dict = register_datasets()\n","\n","    # get metadata for visualization\n","    metadata = metadata_dict[\"val\"]  # use validation metadata\n","\n","    # get default config\n","    cfg = get_default_config()\n","\n","    # load the model\n","    predictor = load_model(cfg)\n","\n","    if predictor is None:\n","        print(\"Failed to load model. Exiting.\")\n","        exit(1)\n","\n","    # example: predict on a single test image\n","    test_image = \"/content/drive/MyDrive/test_image.jpg\"\n","    if os.path.exists(test_image):\n","        print(\"\\nPredicting on test image:\")\n","        outputs, _ = predict_single_image(predictor, test_image, metadata, cfg.OUTPUT_DIR, show_image=True)\n","\n","    # example: predict on all images in test directory\n","    test_dir = \"/content/drive/MyDrive/Coco_Dataset/test\"\n","    if os.path.exists(test_dir):\n","        print(\"\\nPredicting on test directory:\")\n","        output_dir = os.path.join(cfg.OUTPUT_DIR, \"test_predictions\")\n","        results = predict_batch(predictor, test_dir, metadata, output_dir, file_pattern=\"*.jpg\")\n","\n","        # analyze the prediction results\n","        if results:\n","            analyze_predictions(results, metadata)"],"metadata":{"id":"rkpcJiiHXrri"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile utils.py\n","import os\n","import json\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from detectron2.utils.visualizer import Visualizer, ColorMode\n","from detectron2.data import MetadataCatalog\n","\n","def visualize_dataset_samples(dataset_dicts, metadata, output_dir=None, num_samples=3):\n","    # pick some random samples to visualize\n","    import random\n","    random.seed(42)  # for reproducibility\n","\n","    if len(dataset_dicts) <= num_samples:\n","        sample_indices = list(range(len(dataset_dicts)))\n","    else:\n","        sample_indices = random.sample(range(len(dataset_dicts)), num_samples)\n","\n","    # create output directory if specified\n","    if output_dir:\n","        os.makedirs(output_dir, exist_ok=True)\n","\n","    # visualize each sample\n","    for i, idx in enumerate(sample_indices):\n","        d = dataset_dicts[idx]\n","        img = cv2.imread(d[\"file_name\"])\n","\n","        if img is None:\n","            print(f\"Error: Could not read image {d['file_name']}\")\n","            continue\n","\n","        # show file name\n","        print(f\"Sample {i+1}: {os.path.basename(d['file_name'])}\")\n","\n","        # create visualizer for annotations\n","        visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=1.0)\n","        vis = visualizer.draw_dataset_dict(d)\n","        vis_img = vis.get_image()[:, :, ::-1]\n","\n","        # print annotations info\n","        if \"annotations\" in d:\n","            print(f\"  Annotations: {len(d['annotations'])}\")\n","\n","            # count by category\n","            if hasattr(metadata, \"thing_classes\"):\n","                class_counts = {}\n","                for ann in d[\"annotations\"]:\n","                    cat_id = ann[\"category_id\"]\n","                    if cat_id < len(metadata.thing_classes):\n","                        class_name = metadata.thing_classes[cat_id]\n","                        class_counts[class_name] = class_counts.get(class_name, 0) + 1\n","\n","                # print counts by class\n","                for class_name, count in class_counts.items():\n","                    print(f\"    - {class_name}: {count}\")\n","\n","        # save visualization if output directory is specified\n","        if output_dir:\n","            base_name = os.path.splitext(os.path.basename(d[\"file_name\"]))[0]\n","            output_path = os.path.join(output_dir, f\"sample_{i+1}_{base_name}.jpg\")\n","            cv2.imwrite(output_path, vis_img)\n","            print(f\"  Visualization saved to: {output_path}\")\n","\n","        # show the image in notebook\n","        try:\n","            from google.colab.patches import cv2_imshow\n","            cv2_imshow(vis_img)\n","        except:\n","            plt.figure(figsize=(12, 8))\n","            plt.imshow(vis_img[:, :, ::-1])\n","            plt.axis('off')\n","            plt.tight_layout()\n","            plt.show()\n","\n","def get_class_distribution(dataset_dicts, metadata):\n","    # initialize counts\n","    class_counts = {}\n","\n","    # get class names if available\n","    if hasattr(metadata, \"thing_classes\"):\n","        for i, name in enumerate(metadata.thing_classes):\n","            class_counts[name] = 0\n","\n","    # count instances by class\n","    for d in dataset_dicts:\n","        if \"annotations\" not in d:\n","            continue\n","\n","        for ann in d[\"annotations\"]:\n","            cat_id = ann[\"category_id\"]\n","\n","            if hasattr(metadata, \"thing_classes\") and cat_id < len(metadata.thing_classes):\n","                class_name = metadata.thing_classes[cat_id]\n","                class_counts[class_name] = class_counts.get(class_name, 0) + 1\n","            else:\n","                # use category ID as name if name not available\n","                class_name = f\"Class {cat_id}\"\n","                class_counts[class_name] = class_counts.get(class_name, 0) + 1\n","\n","    # print summary\n","    total = sum(class_counts.values())\n","    print(f\"Class distribution ({total} total annotations):\")\n","\n","    for class_name, count in sorted(class_counts.items(), key=lambda x: x[1], reverse=True):\n","        print(f\"  - {class_name}: {count} ({count/total*100:.1f}%)\")\n","\n","    return class_counts\n","\n","def visualize_class_distribution(class_counts, output_path=None):\n","    # sort by count (descending)\n","    sorted_items = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)\n","    class_names = [item[0] for item in sorted_items]\n","    counts = [item[1] for item in sorted_items]\n","\n","    # create the figure\n","    plt.figure(figsize=(10, 6))\n","    bars = plt.bar(class_names, counts, color='skyblue')\n","\n","    # add labels and title\n","    plt.title('Class Distribution in Dataset', fontsize=14)\n","    plt.xlabel('Class', fontsize=12)\n","    plt.ylabel('Count', fontsize=12)\n","    plt.xticks(rotation=45, ha='right')\n","\n","    # add count labels on top of bars\n","    for bar in bars:\n","        height = bar.get_height()\n","        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n","                 f'{int(height)}', ha='center', fontsize=9)\n","\n","    plt.tight_layout()\n","\n","    # save if output path is specified\n","    if output_path:\n","        plt.savefig(output_path)\n","        print(f\"Class distribution saved to: {output_path}\")\n","\n","    # show the plot\n","    plt.show()\n","\n","def export_predictions_to_coco(outputs_list, image_list, output_path):\n","    # create COCO structure\n","    coco_dict = {\n","        \"images\": [],\n","        \"annotations\": [],\n","        \"categories\": []\n","    }\n","\n","    # get metadata for category names\n","    metadata = MetadataCatalog.get(\"my_train_remap\")\n","    if hasattr(metadata, \"thing_classes\"):\n","        categories = metadata.thing_classes\n","\n","        # add categories to COCO structure\n","        for i, name in enumerate(categories):\n","            coco_dict[\"categories\"].append({\n","                \"id\": i,\n","                \"name\": name,\n","                \"supercategory\": \"rice_disease\"\n","            })\n","\n","    # process each prediction\n","    ann_id = 0\n","\n","    for img_id, (outputs, img_path) in enumerate(zip(outputs_list, image_list)):\n","        # read image to get dimensions\n","        img = cv2.imread(img_path)\n","        height, width = img.shape[:2]\n","\n","        # add image info\n","        coco_dict[\"images\"].append({\n","            \"id\": img_id,\n","            \"file_name\": os.path.basename(img_path),\n","            \"width\": width,\n","            \"height\": height\n","        })\n","\n","        # add annotations\n","        instances = outputs[\"instances\"].to(\"cpu\")\n","\n","        if len(instances) > 0:\n","            boxes = instances.pred_boxes.tensor.numpy()\n","            classes = instances.pred_classes.numpy()\n","            scores = instances.scores.numpy()\n","\n","            for box, cls, score in zip(boxes, classes, scores):\n","                # convert box format from [x1, y1, x2, y2] to [x, y, width, height]\n","                x1, y1, x2, y2 = box\n","                x, y, w, h = x1, y1, x2 - x1, y2 - y1\n","\n","                # create annotation\n","                ann = {\n","                    \"id\": ann_id,\n","                    \"image_id\": img_id,\n","                    \"category_id\": int(cls),\n","                    \"bbox\": [float(x), float(y), float(w), float(h)],\n","                    \"area\": float(w * h),\n","                    \"iscrowd\": 0,\n","                    \"score\": float(score)\n","                }\n","\n","                coco_dict[\"annotations\"].append(ann)\n","                ann_id += 1\n","\n","    # write to file\n","    with open(output_path, 'w') as f:\n","        json.dump(coco_dict, f)\n","\n","    print(f\"Exported {ann_id} predictions for {len(image_list)} images to: {output_path}\")\n","    return output_path\n","\n","def draw_bbox_heatmap(outputs_list, image_list, output_path, resolution=(640, 480)):\n","    # create an empty heatmap\n","    heatmap = np.zeros(resolution, dtype=np.float32)\n","\n","    # process each prediction\n","    for outputs, img_path in zip(outputs_list, image_list):\n","        instances = outputs[\"instances\"].to(\"cpu\")\n","\n","        if len(instances) > 0:\n","            # get the image dimensions\n","            img = cv2.imread(img_path)\n","            img_height, img_width = img.shape[:2]\n","\n","            # get predicted boxes\n","            boxes = instances.pred_boxes.tensor.numpy()\n","\n","            # map each box to the heatmap resolution\n","            for box in boxes:\n","                x1, y1, x2, y2 = box\n","\n","                # normalize to [0,1] and scale to heatmap resolution\n","                x1_norm = x1 / img_width * resolution[0]\n","                y1_norm = y1 / img_height * resolution[1]\n","                x2_norm = x2 / img_width * resolution[0]\n","                y2_norm = y2 / img_height * resolution[1]\n","\n","                # convert to int\n","                x1_heat, y1_heat = int(x1_norm), int(y1_norm)\n","                x2_heat, y2_heat = int(x2_norm), int(y2_norm)\n","\n","                # bound check\n","                x1_heat = max(0, min(x1_heat, resolution[0] - 1))\n","                y1_heat = max(0, min(y1_heat, resolution[1] - 1))\n","                x2_heat = max(0, min(x2_heat, resolution[0] - 1))\n","                y2_heat = max(0, min(y2_heat, resolution[1] - 1))\n","\n","                # increment all pixels in the box\n","                heatmap[y1_heat:y2_heat, x1_heat:x2_heat] += 1\n","\n","    # normalize heatmap for visualization\n","    if np.max(heatmap) > 0:\n","        heatmap = heatmap / np.max(heatmap)\n","\n","    # apply colormap\n","    heatmap_colored = cv2.applyColorMap((heatmap * 255).astype(np.uint8), cv2.COLORMAP_JET)\n","\n","    # save the heatmap\n","    cv2.imwrite(output_path, heatmap_colored)\n","    print(f\"Bounding box heatmap saved to: {output_path}\")\n","\n","    return heatmap_colored\n","\n","def print_model_summary(cfg):\n","    print(\"\\nModel Configuration Summary:\")\n","    print(\"=\" * 50)\n","\n","    # model info\n","    print(f\"Model: Faster R-CNN with {cfg.MODEL.BACKBONE.NAME} backbone\")\n","    print(f\"Number of classes: {cfg.MODEL.ROI_HEADS.NUM_CLASSES}\")\n","    print(f\"Weights: {os.path.basename(cfg.MODEL.WEIGHTS)}\")\n","\n","    # input settings\n","    print(\"\\nInput settings:\")\n","    print(f\"  Min size: {cfg.INPUT.MIN_SIZE_TRAIN}\")\n","    print(f\"  Max size: {cfg.INPUT.MAX_SIZE_TRAIN}\")\n","    print(f\"  Format: {cfg.INPUT.FORMAT}\")\n","\n","    # solver settings\n","    print(\"\\nTraining settings:\")\n","    print(f\"  Max iterations: {cfg.SOLVER.MAX_ITER}\")\n","    print(f\"  Base learning rate: {cfg.SOLVER.BASE_LR}\")\n","    print(f\"  Batch size: {cfg.SOLVER.IMS_PER_BATCH}\")\n","    print(f\"  Warmup iterations: {cfg.SOLVER.WARMUP_ITERS}\")\n","    if cfg.SOLVER.STEPS:\n","        print(f\"  LR steps: {cfg.SOLVER.STEPS}\")\n","    else:\n","        print(\"  LR steps: None (constant LR)\")\n","\n","    # dataset info\n","    print(\"\\nDatasets:\")\n","    print(f\"  Train: {cfg.DATASETS.TRAIN}\")\n","    print(f\"  Test: {cfg.DATASETS.TEST}\")\n","\n","    # ROI head settings\n","    print(\"\\nROI Head settings:\")\n","    print(f\"  ROIs per image: {cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE}\")\n","    print(f\"  Score threshold: {cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST}\")\n","\n","    print(\"\\nOutput directory:\")\n","    print(f\"  {cfg.OUTPUT_DIR}\")\n","    print(\"=\" * 50)"],"metadata":{"id":"jh3m3g7dXuQ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile main.py\n","import os\n","import time\n","import argparse\n","from detectron2.utils.logger import setup_logger\n","\n","def print_header(text):\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"{text}\")\n","    print(\"=\"*50)\n","\n","def main():\n","    # set up argument parser\n","    parser = argparse.ArgumentParser(description=\"Rice Leaf Disease Detection with Faster RCNN\")\n","    parser.add_argument(\"--skip-setup\", action=\"store_true\", help=\"Skip setup steps\")\n","    parser.add_argument(\"--skip-train\", action=\"store_true\", help=\"Skip training\")\n","    parser.add_argument(\"--skip-evaluate\", action=\"store_true\", help=\"Skip evaluation\")\n","    parser.add_argument(\"--skip-predict\", action=\"store_true\", help=\"Skip prediction\")\n","    parser.add_argument(\"--test-image\", type=str, help=\"Path to a test image for prediction\")\n","    parser.add_argument(\"--test-dir\", type=str, help=\"Path to a directory of test images\")\n","    parser.add_argument(\"--resume\", action=\"store_true\", help=\"Resume training from last checkpoint\")\n","    parser.add_argument(\"--debug\", action=\"store_true\", help=\"Run in debug mode with more output\")\n","    args = parser.parse_args()\n","\n","    # time the execution\n","    start_time = time.time()\n","\n","    # set up logger\n","    setup_logger()\n","\n","    # Step 1: Setup\n","    if not args.skip_setup:\n","        print_header(\"SETUP\")\n","        from setup import mount_drive, check_gpu, check_dataset, install_dependencies\n","\n","        # mount Google Drive\n","        mount_drive()\n","\n","        # check GPU\n","        gpu_available = check_gpu()\n","        if not gpu_available and not args.skip_train:\n","            print(\"Warning: No GPU detected. Training will be extremely slow.\")\n","            response = input(\"Continue anyway? (y/n): \")\n","            if response.lower() != 'y':\n","                return\n","\n","        # check dataset\n","        dataset_ok = check_dataset()\n","        if not dataset_ok:\n","            print(\"Warning: Dataset issues detected.\")\n","            response = input(\"Continue anyway? (y/n): \")\n","            if response.lower() != 'y':\n","                return\n","\n","        # install dependencies\n","        deps_ok = install_dependencies()\n","        if not deps_ok:\n","            print(\"Error installing dependencies. Please check the logs.\")\n","            return\n","\n","    # Step 2: Register datasets\n","    print_header(\"DATASET REGISTRATION\")\n","    from data import register_datasets, print_dataset_stats\n","\n","    # register the datasets\n","    metadata_dict = register_datasets()\n","\n","    # print dataset statistics\n","    if args.debug:\n","        print_dataset_stats()\n","\n","    # get the configuration\n","    from config import get_default_config\n","    cfg = get_default_config()\n","\n","    # print model configuration\n","    if args.debug:\n","        from utils import print_model_summary\n","        print_model_summary(cfg)\n","\n","    # Step 3: Training\n","    if not args.skip_train:\n","        print_header(\"TRAINING\")\n","        from train import train_model, save_model_config\n","\n","        # save model configuration\n","        save_model_config(cfg)\n","\n","        # train the model\n","        success, trainer = train_model(cfg, resume=args.resume)\n","\n","        if not success:\n","            print(\"Training failed. Cannot continue to evaluation.\")\n","            return\n","\n","    # Step 4: Evaluation\n","    if not args.skip_evaluate:\n","        print_header(\"EVALUATION\")\n","        from evaluate import evaluate_model, debug_validation_samples, analyze_failure_cases\n","\n","        # evaluate on validation set\n","        eval_results = evaluate_model(cfg, \"my_val_remap\")\n","\n","        # debug validation samples if in debug mode\n","        if args.debug:\n","            debug_validation_samples(cfg, \"my_val_remap\", max_images=3)\n","            analyze_failure_cases(cfg, \"my_val_remap\", iou_threshold=0.5, max_images=5)\n","\n","    # Step 5: Prediction\n","    if not args.skip_predict:\n","        print_header(\"PREDICTION\")\n","        from predict import load_model, predict_single_image, predict_batch\n","\n","        # load the model\n","        predictor = load_model(cfg)\n","\n","        if predictor is None:\n","            print(\"Failed to load model. Cannot run predictions.\")\n","            return\n","\n","        # get metadata for visualization\n","        metadata = metadata_dict[\"test\"]\n","\n","        # predict on a single test image if specified\n","        if args.test_image and os.path.exists(args.test_image):\n","            print(\"\\nPredicting on specified test image:\")\n","            predict_single_image(predictor, args.test_image, metadata, cfg.OUTPUT_DIR, show_image=True)\n","\n","        # predict on a directory of test images if specified\n","        if args.test_dir and os.path.exists(args.test_dir):\n","            print(\"\\nPredicting on test directory:\")\n","            output_dir = os.path.join(cfg.OUTPUT_DIR, \"predictions\")\n","            predict_batch(predictor, args.test_dir, metadata, output_dir)\n","\n","        # if no specific test image or directory is specified, run on the test set\n","        if not args.test_image and not args.test_dir:\n","            from config import TEST_IMG\n","\n","            if os.path.exists(TEST_IMG):\n","                print(\"\\nPredicting on default test set:\")\n","                output_dir = os.path.join(cfg.OUTPUT_DIR, \"test_predictions\")\n","                predict_batch(predictor, TEST_IMG, metadata, output_dir)\n","\n","    # Done\n","    total_time = (time.time() - start_time) / 60\n","    print_header(\"COMPLETED\")\n","    print(f\"Total time: {total_time:.2f} minutes\")\n","    print(\"Rice Leaf Disease Detection with Faster RCNN completed!\")\n","\n","if __name__ == \"__main__\":\n","    print(\"RICE LEAF DISEASE DETECTION WITH FASTER RCNN\")\n","    print(\"A Detectron2 implementation for rice leaf disease detection\")\n","    main()\n"],"metadata":{"id":"w-VrufohYXPF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","\n","# Đường dẫn thư mục gốc và các thư mục con\n","data_root = \"/content/drive/MyDrive/Coco_Dataset\"\n","train_dir = os.path.join(data_root, \"train\")\n","val_dir = os.path.join(data_root, \"valid\")\n","test_dir = os.path.join(data_root, \"test\")\n","\n","train_json = os.path.join(train_dir, \"_annotations.coco.json\")\n","val_json = os.path.join(val_dir, \"_annotations.coco.json\")\n","test_json = os.path.join(test_dir, \"_annotations.coco.json\")\n","\n","# Kiểm tra thư mục và file annotation\n","print(\"Kiểm tra cấu trúc dữ liệu:\")\n","print(f\"Đường dẫn gốc: {data_root}\")\n","\n","# Kiểm tra thư mục\n","for dir_path, dir_name in [(train_dir, \"train\"), (val_dir, \"valid\"), (test_dir, \"test\")]:\n","    if os.path.exists(dir_path):\n","        print(f\"✅ Thư mục {dir_name} tồn tại\")\n","        files = os.listdir(dir_path)\n","        img_files = [f for f in files if f.endswith(('.jpg', '.jpeg', '.png'))]\n","        print(f\"   - Số lượng ảnh: {len(img_files)}\")\n","    else:\n","        print(f\"❌ Thư mục {dir_name} không tồn tại\")\n","\n","# Kiểm tra file annotation\n","for json_path, json_name in [(train_json, \"train\"), (val_json, \"valid\"), (test_json, \"test\")]:\n","    if os.path.exists(json_path):\n","        print(f\"✅ File annotation {json_name} tồn tại\")\n","\n","        # Đọc và hiển thị thông tin từ file JSON\n","        try:\n","            with open(json_path, 'r') as f:\n","                data = json.load(f)\n","                print(f\"   - Số lượng ảnh trong annotation: {len(data.get('images', []))}\")\n","                print(f\"   - Số lượng annotation: {len(data.get('annotations', []))}\")\n","                print(f\"   - Số lượng category: {len(data.get('categories', []))}\")\n","\n","                # Hiển thị thông tin về các category\n","                if 'categories' in data:\n","                    print(\"   - Danh sách category:\")\n","                    for cat in data['categories']:\n","                        print(f\"     + ID: {cat['id']}, Tên: {cat.get('name', 'Không có tên')}\")\n","        except Exception as e:\n","            print(f\"   - Lỗi khi đọc file JSON: {e}\")\n","    else:\n","        print(f\"❌ File annotation {json_name} không tồn tại\")"],"metadata":{"id":"x9IKerIxYiz6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from setup import mount_drive, check_gpu, check_dataset, install_dependencies\n","from data import register_datasets, print_dataset_stats\n","\n","print(\"==== THIẾT LẬP DỰ ÁN ====\")\n","# Kết nối Google Drive\n","mount_drive()\n","\n","# Kiểm tra GPU\n","check_gpu()\n","\n","# Kiểm tra dữ liệu\n","check_dataset()\n","\n","# Cài đặt các thư viện cần thiết\n","install_dependencies()\n","\n","print(\"\\n==== ĐĂNG KÝ DỮ LIỆU ====\")\n","# Đăng ký các tập dữ liệu\n","metadata_dict = register_datasets()\n","\n","# In thống kê về dữ liệu\n","print(\"\\n==== THỐNG KÊ DỮ LIỆU ====\")\n","print_dataset_stats()"],"metadata":{"id":"HLoya9qUYm0D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from detectron2.data import DatasetCatalog, MetadataCatalog\n","from utils import visualize_dataset_samples, get_class_distribution, visualize_class_distribution\n","from config import TRAIN_REMAP_DATASET, VAL_REMAP_DATASET, TEST_REMAP_DATASET, OUTPUT_DIR\n","import os\n","\n","print(\"==== KHÁM PHÁ DỮ LIỆU ====\")\n","\n","# Lấy metadata của tập huấn luyện\n","train_metadata = MetadataCatalog.get(TRAIN_REMAP_DATASET)\n","# Lấy dữ liệu huấn luyện\n","train_dicts = DatasetCatalog.get(TRAIN_REMAP_DATASET)\n","\n","# Hiển thị một số mẫu từ tập huấn luyện\n","print(\"\\nHiển thị một số mẫu từ tập huấn luyện:\")\n","# Tạo thư mục để lưu trữ hình ảnh mẫu\n","samples_dir = os.path.join(OUTPUT_DIR, \"dataset_samples\")\n","os.makedirs(samples_dir, exist_ok=True)\n","# Hiển thị 3 mẫu\n","visualize_dataset_samples(train_dicts, train_metadata, samples_dir, num_samples=3)\n","\n","# Phân tích phân bố lớp\n","print(\"\\nPhân tích phân bố lớp trong tập huấn luyện:\")\n","class_counts = get_class_distribution(train_dicts, train_metadata)\n","\n","# Vẽ biểu đồ phân bố lớp\n","class_dist_path = os.path.join(OUTPUT_DIR, \"class_distribution.png\")\n","visualize_class_distribution(class_counts, class_dist_path)\n"],"metadata":{"id":"xKLnbGsmYqr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from config import get_default_config\n","from utils import print_model_summary\n","from train import save_model_config\n","\n","print(\"==== CHUẨN BỊ HUẤN LUYỆN ====\")\n","\n","# Lấy cấu hình mặc định cho mô hình\n","cfg = get_default_config()\n","\n","# In tóm tắt về cấu hình mô hình\n","print_model_summary(cfg)\n","\n","# Lưu cấu hình mô hình để tham khảo sau này\n","save_model_config(cfg)\n","\n","# Hiển thị số thông số của mô hình\n","print(\"\\nSố lượng iteration huấn luyện:\", cfg.SOLVER.MAX_ITER)\n","print(\"Batch size:\", cfg.SOLVER.IMS_PER_BATCH)\n","print(\"Learning rate:\", cfg.SOLVER.BASE_LR)\n","print(\"Đường dẫn lưu trữ:\", cfg.OUTPUT_DIR)"],"metadata":{"id":"dWRryqTIYsrP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from train import train_model\n","\n","print(\"==== BẮT ĐẦU HUẤN LUYỆN ====\")\n","\n","# Từ checkpoint đợt trước (mất kết nối) => resume = True\n","success, trainer = train_model(cfg, resume=True)\n","\n","if success:\n","    print(\"Huấn luyện hoàn tất thành công!\")\n","else:\n","    print(\"Huấn luyện thất bại. Kiểm tra lỗi trong log.\")"],"metadata":{"id":"aDvULWj7Yzwa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from evaluate import evaluate_model, debug_validation_samples\n","\n","print(\"==== ĐÁNH GIÁ MÔ HÌNH ====\")\n","\n","# Đánh giá mô hình trên tập validation\n","eval_results = evaluate_model(cfg, \"my_val_remap\")\n","\n","# Debug một số mẫu từ tập validation\n","print(\"\\nPhân tích một số mẫu dự đoán từ tập validation:\")\n","debug_validation_samples(cfg, \"my_val_remap\", max_images=3)"],"metadata":{"id":"KHMW_yEjZG5S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from predict import load_model, predict_batch, analyze_predictions\n","from config import TEST_IMG\n","\n","print(\"==== DỰ ĐOÁN TRÊN TẬP TEST ====\")\n","\n","# Tải mô hình đã huấn luyện\n","predictor = load_model(cfg)\n","\n","if predictor is None:\n","    print(\"Không thể tải mô hình. Kiểm tra đường dẫn.\")\n","else:\n","    # Tạo thư mục để lưu kết quả dự đoán\n","    output_dir = os.path.join(cfg.OUTPUT_DIR, \"test_predictions\")\n","\n","    # Dự đoán trên tập test\n","    print(\"\\nĐang dự đoán trên tập test:\")\n","    results = predict_batch(predictor, TEST_IMG, metadata_dict[\"test\"], output_dir)\n","\n","    # Phân tích kết quả dự đoán\n","    if results:\n","        print(\"\\nPhân tích kết quả dự đoán:\")\n","        analyze_predictions(results, metadata_dict[\"test\"])"],"metadata":{"id":"9tNa-9eyZLMR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from evaluate import analyze_failure_cases\n","\n","print(\"==== PHÂN TÍCH LỖI CHI TIẾT ====\")\n","\n","# Phân tích các trường hợp dự đoán sai/lỗi\n","analyze_failure_cases(cfg, \"my_val_remap\", iou_threshold=0.5, max_images=10)"],"metadata":{"id":"8jQ7UFIOZODu"},"execution_count":null,"outputs":[]}]}